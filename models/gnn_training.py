import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv, SAGEConv, HeteroConv, Linear
from torch_geometric.utils import train_test_split_edges
from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score
import matplotlib.pyplot as plt
from pathlib import Path
import json
import warnings

warnings.filterwarnings('ignore')


class EventGCN(nn.Module):

    def __init__(self, input_dim, hidden_dim=64, output_dim=32, num_layers=2, dropout=0.5):
        super(EventGCN, self).__init__()

        self.convs = nn.ModuleList()
        self.convs.append(GCNConv(input_dim, hidden_dim))

        for _ in range(num_layers - 2):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))

        self.convs.append(GCNConv(hidden_dim, output_dim))

        self.dropout = dropout

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < len(self.convs) - 1:
                x = F.relu(x)
                x = F.dropout(x, p=self.dropout, training=self.training)
        return x


class EventGAT(nn.Module):

    def __init__(self, input_dim, hidden_dim=64, output_dim=32, num_layers=2, heads=4, dropout=0.5):
        super(EventGAT, self).__init__()

        self.convs = nn.ModuleList()
        self.convs.append(GATConv(input_dim, hidden_dim // heads, heads=heads, dropout=dropout))

        for _ in range(num_layers - 2):
            self.convs.append(GATConv(hidden_dim, hidden_dim // heads, heads=heads, dropout=dropout))

        self.convs.append(GATConv(hidden_dim, output_dim, heads=1, dropout=dropout))

        self.dropout = dropout

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < len(self.convs) - 1:
                x = F.relu(x)
                x = F.dropout(x, p=self.dropout, training=self.training)
        return x


class EventGraphSAGE(nn.Module):

    def __init__(self, input_dim, hidden_dim=64, output_dim=32, num_layers=2, dropout=0.5):
        super(EventGraphSAGE, self).__init__()

        self.convs = nn.ModuleList()
        self.convs.append(SAGEConv(input_dim, hidden_dim))

        for _ in range(num_layers - 2):
            self.convs.append(SAGEConv(hidden_dim, hidden_dim))

        self.convs.append(SAGEConv(hidden_dim, output_dim))
        self.dropout = dropout

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < len(self.convs) - 1:
                x = F.relu(x)
                x = F.dropout(x, p=self.dropout, training=self.training)
        return x


class GNNTrainer:

    def __init__(self, graph_data_dir="../graph_construction/graph_data", output_dir="gnn_results"):
        self.graph_data_dir = Path(graph_data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        self.graphs = {}
        self.models = {}
        self.results = {}

        print(f"üìÇ Graph data dir: {self.graph_data_dir.absolute()}")
        print(f"üìÅ Output dir: {self.output_dir.absolute()}")

        self.load_metadata()

    def load_metadata(self):
        metadata_file = self.graph_data_dir / "graph_metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)
            print(f"‚úÖ –ú–µ—Ç–∞–ø–æ–¥–∞—Ç–æ—Ü–∏ –≤—á–∏—Ç–∞–Ω–∏: {len(self.metadata.get('graphs_created', []))} –≥—Ä–∞—Ñ–æ–≤–∏")
        else:
            print("‚ö†Ô∏è –ù–µ–º–∞ –º–µ—Ç–∞–ø–æ–¥–∞—Ç–æ—Ü–∏, –∫–æ—Ä–∏—Å—Ç–∞–º default –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏")
            self.metadata = {}

    def load_graphs(self):
        print("üìÇ –í—á–∏—Ç—É–≤–∞—ö–µ –≥—Ä–∞—Ñ–æ–≤–∏...")

        if not self.graph_data_dir.exists():
            print(f"‚ùå –ü–∞–ø–∫–∞—Ç–∞ –Ω–µ –ø–æ—Å—Ç–æ–∏: {self.graph_data_dir}")
            return False

        graph_files = list(self.graph_data_dir.glob("*_graph.pt"))

        if not graph_files:
            print("‚ùå –ù–µ–º–∞ .pt —Ñ–∞—ò–ª–æ–≤–∏ –≤–æ graph_data –ø–∞–ø–∫–∞—Ç–∞!")
            print(f"üîç –ü—Ä–æ–≤–µ—Ä—É–≤–∞–º –ø–∞–ø–∫–∞: {self.graph_data_dir}")
            print("üìã –°–æ–¥—Ä–∂–∏–Ω–∞:")
            for item in self.graph_data_dir.iterdir():
                print(f"   - {item.name}")
            return False

        for graph_file in graph_files:
            graph_name = graph_file.stem.replace("_graph", "")
            try:
                graph = torch.load(graph_file, map_location='cpu', weights_only=False)
                self.graphs[graph_name] = graph
                print(f"   ‚úÖ {graph_name}: {type(graph).__name__}")

                if hasattr(graph, 'x') and hasattr(graph, 'edge_index'):
                    print(f"      Nodes: {graph.x.shape[0]}, Features: {graph.x.shape[1]}")
                    if graph.edge_index.shape[1] > 0:
                        print(f"      Edges: {graph.edge_index.shape[1]}")
                    else:
                        print(f"      Edges: 0 (—Å–∞–º–æ nodes)")

            except Exception as e:
                print(f"   ‚ùå –ü—Ä–æ–±–ª–µ–º —Å–æ {graph_name}: {e}")

        return len(self.graphs) > 0

    def prepare_node_classification_data(self, graph_name="event_similarity"):
        print(f"üéØ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞ node classification ({graph_name})...")

        if graph_name not in self.graphs:
            print(f"‚ùå –ì—Ä–∞—Ñ–æ—Ç {graph_name} –Ω–µ –ø–æ—Å—Ç–æ–∏!")
            available_graphs = list(self.graphs.keys())
            print(f"üìã –î–æ—Å—Ç–∞–ø–Ω–∏ –≥—Ä–∞—Ñ–æ–≤–∏: {available_graphs}")
            if available_graphs:
                graph_name = available_graphs[0]
                print(f"üîÑ –ö–æ—Ä–∏—Å—Ç–∞–º {graph_name} –Ω–∞–º–µ—Å—Ç–æ —Ç–æ–∞")
            else:
                return None

        graph = self.graphs[graph_name]

        num_nodes = graph.x.shape[0]

        features = graph.x.numpy()

        if features.shape[1] > 10:  # –ê–∫–æ –∏–º–∞–º–µ TF-IDF features
            from sklearn.cluster import KMeans
            n_clusters = min(5, max(2, num_nodes // 10))  # 2-5 –∫–ª–∞—Å—Ç–µ—Ä–∏
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            labels = kmeans.fit_predict(features)
        else:
            labels = np.random.randint(0, 3, size=num_nodes)

        train_mask = torch.zeros(num_nodes, dtype=torch.bool)
        test_mask = torch.zeros(num_nodes, dtype=torch.bool)
        val_mask = torch.zeros(num_nodes, dtype=torch.bool)

        indices = np.random.permutation(num_nodes)
        train_size = int(0.6 * num_nodes)
        val_size = int(0.2 * num_nodes)

        train_mask[indices[:train_size]] = True
        val_mask[indices[train_size:train_size + val_size]] = True
        test_mask[indices[train_size + val_size:]] = True

        graph.y = torch.tensor(labels, dtype=torch.long)
        graph.train_mask = train_mask
        graph.val_mask = val_mask
        graph.test_mask = test_mask

        print(f"   ‚úÖ Labels: {len(np.unique(labels))} –∫–ª–∞—Å–∏")
        print(f"   ‚úÖ Train: {train_mask.sum()}, Val: {val_mask.sum()}, Test: {test_mask.sum()}")

        return graph

    def train_node_classification(self, graph_name="event_similarity", model_type="GCN"):
        """–¢—Ä–µ–Ω–∏—Ä–∞—ò –º–æ–¥–µ–ª –∑–∞ node classification"""
        print(f"üöÄ –¢—Ä–µ–Ω–∏—Ä–∞—ö–µ {model_type} –∑–∞ node classification...")

        graph = self.prepare_node_classification_data(graph_name)
        if graph is None:
            return None

        input_dim = graph.x.shape[1]
        num_classes = len(torch.unique(graph.y))

        if model_type == "GCN":
            model = EventGCN(input_dim, hidden_dim=64, output_dim=num_classes)
        elif model_type == "GAT":
            model = EventGAT(input_dim, hidden_dim=64, output_dim=num_classes)
        elif model_type == "GraphSAGE":
            model = EventGraphSAGE(input_dim, hidden_dim=64, output_dim=num_classes)
        else:
            print(f"‚ùå –ù–µ–ø–æ–∑–Ω–∞—Ç model type: {model_type}")
            return None

        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
        criterion = nn.CrossEntropyLoss()

        model.train()
        train_losses = []
        val_accuracies = []

        for epoch in range(200):
            optimizer.zero_grad()

            out = model(graph.x, graph.edge_index)
            loss = criterion(out[graph.train_mask], graph.y[graph.train_mask])

            loss.backward()
            optimizer.step()

            if epoch % 20 == 0:
                model.eval()
                with torch.no_grad():
                    val_out = model(graph.x, graph.edge_index)
                    val_pred = val_out[graph.val_mask].argmax(dim=1)
                    val_acc = accuracy_score(graph.y[graph.val_mask].cpu(), val_pred.cpu())
                    val_accuracies.append(val_acc)

                    print(f"   Epoch {epoch:3d}: Loss={loss:.4f}, Val Acc={val_acc:.4f}")

                model.train()

            train_losses.append(loss.item())

        model.eval()
        with torch.no_grad():
            test_out = model(graph.x, graph.edge_index)
            test_pred = test_out[graph.test_mask].argmax(dim=1)
            test_acc = accuracy_score(graph.y[graph.test_mask].cpu(), test_pred.cpu())
            test_f1 = f1_score(graph.y[graph.test_mask].cpu(), test_pred.cpu(), average='weighted')

        results = {
            'model_type': model_type,
            'graph_name': graph_name,
            'test_accuracy': test_acc,
            'test_f1': test_f1,
            'num_classes': num_classes,
            'train_losses': train_losses,
            'val_accuracies': val_accuracies
        }

        print(f"   ‚úÖ Test Accuracy: {test_acc:.4f}")
        print(f"   ‚úÖ Test F1: {test_f1:.4f}")

        model_key = f"{model_type}_{graph_name}"
        self.models[model_key] = model
        self.results[model_key] = results

        return results

    def train_link_prediction(self, graph_name="event_similarity"):
        print(f"üîó –¢—Ä–µ–Ω–∏—Ä–∞—ö–µ –∑–∞ link prediction ({graph_name})...")

        if graph_name not in self.graphs:
            available_graphs = list(self.graphs.keys())
            if available_graphs:
                graph_name = available_graphs[0]
                print(f"üîÑ –ö–æ—Ä–∏—Å—Ç–∞–º {graph_name} –Ω–∞–º–µ—Å—Ç–æ event_similarity")
            else:
                print("‚ùå –ù–µ–º–∞ –¥–æ—Å—Ç–∞–ø–Ω–∏ –≥—Ä–∞—Ñ–æ–≤–∏!")
                return None

        graph = self.graphs[graph_name]

        if not hasattr(graph, 'edge_index') or graph.edge_index.shape[1] == 0:
            print("‚ùå –ì—Ä–∞—Ñ–æ—Ç –Ω–µ–º–∞ edges –∑–∞ link prediction!")
            return None

        data = train_test_split_edges(graph, val_ratio=0.1, test_ratio=0.2)

        model = EventGraphSAGE(
            input_dim=graph.x.shape[1],
            hidden_dim=64,
            output_dim=32
        )

        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

        model.train()
        for epoch in range(100):
            optimizer.zero_grad()

            z = model(data.x, data.train_pos_edge_index)

            edge_index = data.train_pos_edge_index
            pos_scores = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)

            neg_edge_index = torch.randint(0, data.num_nodes, edge_index.shape)
            neg_scores = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=1)

            scores = torch.cat([pos_scores, neg_scores])
            labels = torch.cat([torch.ones(pos_scores.size(0)), torch.zeros(neg_scores.size(0))])

            loss = F.binary_cross_entropy_with_logits(scores, labels)
            loss.backward()
            optimizer.step()

            if epoch % 20 == 0:
                print(f"   Epoch {epoch:3d}: Loss={loss:.4f}")

        model.eval()
        with torch.no_grad():
            z = model(data.x, data.train_pos_edge_index)

            test_pos_scores = (z[data.test_pos_edge_index[0]] * z[data.test_pos_edge_index[1]]).sum(dim=1)
            test_neg_scores = (z[data.test_neg_edge_index[0]] * z[data.test_neg_edge_index[1]]).sum(dim=1)

            test_scores = torch.cat([test_pos_scores, test_neg_scores])
            test_labels = torch.cat([torch.ones(test_pos_scores.size(0)), torch.zeros(test_neg_scores.size(0))])

            test_auc = roc_auc_score(test_labels.cpu(), test_scores.cpu())

        results = {
            'model_type': 'GraphSAGE_LinkPred',
            'graph_name': graph_name,
            'test_auc': test_auc,
            'embeddings': z.detach().cpu().numpy()
        }

        print(f"   ‚úÖ Test AUC: {test_auc:.4f}")

        self.results[f"LinkPred_{graph_name}"] = results
        return results

    def visualize_results(self):
        print("üé® –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏...")

        if not self.results:
            print("‚ùå –ù–µ–º–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞!")
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        node_clf_results = {k: v for k, v in self.results.items() if 'test_accuracy' in v}

        if node_clf_results:
            models = list(node_clf_results.keys())
            accuracies = [node_clf_results[m]['test_accuracy'] for m in models]
            f1_scores = [node_clf_results[m]['test_f1'] for m in models]

            x = range(len(models))
            width = 0.35

            axes[0, 0].bar([i - width / 2 for i in x], accuracies, width, label='Accuracy', alpha=0.8)
            axes[0, 0].bar([i + width / 2 for i in x], f1_scores, width, label='F1-Score', alpha=0.8)
            axes[0, 0].set_ylabel('Score')
            axes[0, 0].set_title('üéØ Node Classification Performance')
            axes[0, 0].set_xticks(x)
            axes[0, 0].set_xticklabels([m.replace('_', '\n') for m in models], rotation=45)
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)

        first_model = list(node_clf_results.keys())[0] if node_clf_results else None
        if first_model and 'train_losses' in self.results[first_model]:
            losses = self.results[first_model]['train_losses']
            axes[0, 1].plot(losses, label='Training Loss')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Loss')
            axes[0, 1].set_title('üìà Training Progress')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)

        link_pred_results = {k: v for k, v in self.results.items() if 'test_auc' in v}

        if link_pred_results:
            models = list(link_pred_results.keys())
            aucs = [link_pred_results[m]['test_auc'] for m in models]

            axes[1, 0].bar(range(len(models)), aucs, alpha=0.8, color='green')
            axes[1, 0].set_ylabel('AUC Score')
            axes[1, 0].set_title('üîó Link Prediction Performance')
            axes[1, 0].set_xticks(range(len(models)))
            axes[1, 0].set_xticklabels([m.replace('_', '\n') for m in models])
            axes[1, 0].grid(True, alpha=0.3)

        total_models = len(self.results)
        avg_accuracy = np.mean([r['test_accuracy'] for r in node_clf_results.values()]) if node_clf_results else 0
        avg_auc = np.mean([r['test_auc'] for r in link_pred_results.values()]) if link_pred_results else 0

        summary_text = f"""
        üìä –†–ï–ó–£–õ–¢–ê–¢–ò –†–ï–ó–ò–ú–ï

        üß† –ú–æ–¥–µ–ª–∏ —Ç—Ä–µ–Ω–∏—Ä–∞–Ω–∏: {total_models}

        üéØ Node Classification:
        ‚Ä¢ –ü—Ä–æ—Å–µ—á–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç: {avg_accuracy:.3f}

        üîó Link Prediction:
        ‚Ä¢ –ü—Ä–æ—Å–µ—á–µ–Ω AUC: {avg_auc:.3f}

        üìà –ì—Ä–∞—Ñ–æ–≤–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏:
        {', '.join(set(r.get('graph_name', 'unknown') for r in self.results.values()))}
        """

        axes[1, 1].text(0.1, 0.5, summary_text, transform=axes[1, 1].transAxes,
                        fontsize=10, verticalalignment='center',
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
        axes[1, 1].set_xlim(0, 1)
        axes[1, 1].set_ylim(0, 1)
        axes[1, 1].axis('off')

        plt.tight_layout()
        plt.savefig(self.output_dir / 'gnn_training_results.png', dpi=200, bbox_inches='tight')
        plt.close()

        print(f"   ‚úÖ –†–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞—á—É–≤–∞–Ω–∏ –≤–æ: {self.output_dir}")

    def save_results(self):
        print("üíæ –ó–∞—á—É–≤—É–≤–∞—ö–µ –º–æ–¥–µ–ª–∏ –∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏...")

        models_dir = self.output_dir / "models"
        models_dir.mkdir(exist_ok=True)

        for model_name, model in self.models.items():
            model_path = models_dir / f"{model_name}.pt"
            torch.save(model.state_dict(), model_path)
            print(f"   ‚úÖ {model_name}.pt")

        results_clean = {}
        for key, result in self.results.items():
            clean_result = {k: v for k, v in result.items()
                            if not isinstance(v, np.ndarray)}  # –ò–∑–±–µ–≥–Ω–∏ numpy arrays –≤–æ JSON
            results_clean[key] = clean_result

        with open(self.output_dir / 'training_results.json', 'w', encoding='utf-8') as f:
            json.dump(results_clean, f, indent=2, ensure_ascii=False)

        print(f"   ‚úÖ training_results.json")
        print(f"üíæ –°√® –∑–∞—á—É–≤–∞–Ω–æ –≤–æ: {self.output_dir}")

    def run_full_training(self):
        """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞ –∑–∞ —Ç—Ä–µ–Ω–∏—Ä–∞—ö–µ"""
        print("üß† GNN Training System")
        print("=" * 50)

        if not self.load_graphs():
            print("‚ùå –ù–µ –º–æ–∂–∞–º –¥–∞ –≥–∏ –≤—á–∏—Ç–∞–º –≥—Ä–∞—Ñ–æ–≤–∏—Ç–µ!")
            return False

        print("\nüéØ NODE CLASSIFICATION")
        print("-" * 30)

        available_graphs = list(self.graphs.keys())
        target_graph = available_graphs[0] if available_graphs else "event_similarity"

        for model_type in ["GCN", "GAT", "GraphSAGE"]:
            try:
                self.train_node_classification(target_graph, model_type)
            except Exception as e:
                print(f"‚ùå –ü—Ä–æ–±–ª–µ–º —Å–æ {model_type}: {e}")

        print("\nüîó LINK PREDICTION")
        print("-" * 30)

        try:
            self.train_link_prediction(target_graph)
        except Exception as e:
            print(f"‚ùå –ü—Ä–æ–±–ª–µ–º —Å–æ link prediction: {e}")

        self.visualize_results()
        self.save_results()

        print("\nüéâ GNN Training –∑–∞–≤—Ä—à–µ–Ω!")
        return True


def main():
    trainer = GNNTrainer()
    success = trainer.run_full_training()

    if success:
        print("\n‚úÖ –°√® –≥–æ—Ç–æ–≤–æ! –ü—Ä–æ–≤–µ—Ä–∏ —ò–∞ 'gnn_results' –ø–∞–ø–∫–∞—Ç–∞ –∑–∞:")
        print("   üìä training_results.json - –¥–µ—Ç–∞–ª–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏")
        print("   üß† models/ - —Ç—Ä–µ–Ω–∏—Ä–∞–Ω–∏ –º–æ–¥–µ–ª–∏")
        print("   üé® gnn_training_results.png - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        print("\nüí° –°–ª–µ–¥–µ–Ω —á–µ–∫–æ—Ä: –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–∞—ò —Å–æ —Ä–∞–∑–ª–∏—á–Ω–∏ hyperparameters!")

    return success


if __name__ == "__main__":
    main()