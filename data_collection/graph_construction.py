import pandas as pd
import numpy as np
import networkx as nx
import torch
from torch_geometric.data import Data, HeteroData
from torch_geometric.utils import from_networkx, to_networkx
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder, StandardScaler
import matplotlib.pyplot as plt
from pathlib import Path
import json
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')


class GraphConstructor:
    """–ö—Ä–µ–∏—Ä–∞ –≥—Ä–∞—Ñ–æ–≤–∏ –æ–¥ event –ø–æ–¥–∞—Ç–æ—Ü–∏"""

    def __init__(self, data_dir=None, output_dir="../graph_construction/graph_data"):
        if data_dir is None:
            data_dir = self.find_cleaned_data_dir()

        self.data_dir = Path(data_dir) if data_dir else None
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        self.df = pd.DataFrame()
        self.graphs = {}
        self.stats = {}

        # Feature encoders
        self.label_encoders = {}
        self.scaler = StandardScaler()

    def find_cleaned_data_dir(self):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç—Å–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏—ò–∞ –Ω–∞ cleaned_data –ø–∞–ø–∫–∞—Ç–∞"""
        print("üîç –ë–∞—Ä–∞–º cleaned_data –ø–∞–ø–∫–∞...")

        # –ü—Ä–æ—à–∏—Ä–µ–Ω–∞ –ª–∏—Å—Ç–∞ –Ω–∞ –º–æ–∂–Ω–∏ –ø–∞—Ç–∏—à—Ç–∞
        possible_paths = [
            # –¢–µ–∫–æ–≤–Ω–∞ –ø–∞–ø–∫–∞
            Path("cleaned_data"),
            Path("NLP_data/cleaned_data"),

            # data_collection –ø–∞–ø–∫–∞
            Path("data_collection/cleaned_data"),
            Path("data_collection/NLP_data/cleaned_data"),  # ‚úÖ –î–û–î–ê–î–ï–ù–û!

            # –ï–¥–µ–Ω –Ω–∏–≤–æ –Ω–∞–≥–æ—Ä–µ
            Path("../cleaned_data"),
            Path("../data_collection/cleaned_data"),
            Path("../data_collection/NLP_data/cleaned_data"),  # ‚úÖ –î–û–î–ê–î–ï–ù–û!

            # graph_construction –ø–∞–ø–∫–∞
            Path("../graph_construction/graph_data"),
            Path("graph_construction/graph_data"),

            # Root –Ω–∞ –ø—Ä–æ–µ–∫—Ç–æ—Ç
            Path("../../data_collection/NLP_data/cleaned_data"),  # ‚úÖ –î–û–î–ê–î–ï–ù–û!
        ]

        for path in possible_paths:
            print(f"   üîç –ü—Ä–æ–≤–µ—Ä—É–≤–∞–º: {path}")
            if path.exists():
                # –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ –∏–º–∞ CSV —Ñ–∞—ò–ª–æ–≤–∏
                csv_files = list(path.glob("*.csv"))
                if csv_files:
                    print(f"   ‚úÖ –ü—Ä–æ–Ω–∞—ò–¥–µ–Ω–∞ —Å–æ {len(csv_files)} CSV —Ñ–∞—ò–ª–æ–≤–∏: {path}")
                    return str(path)
                else:
                    print(f"   ‚ö†Ô∏è –ü–∞–ø–∫–∞—Ç–∞ –ø–æ—Å—Ç–æ–∏ –Ω–æ –Ω–µ–º–∞ CSV —Ñ–∞—ò–ª–æ–≤–∏: {path}")
            else:
                print(f"   ‚ùå –ù–µ –ø–æ—Å—Ç–æ–∏: {path}")

        print("‚ùå –ù–µ –º–æ–∂–∞–º –¥–∞ –Ω–∞—ò–¥–∞–º cleaned_data –ø–∞–ø–∫–∞!")
        return None

    def load_data(self):
        """–í—á–∏—Ç–∞—ò cleaned –ø–æ–¥–∞—Ç–æ—Ü–∏"""
        print("üìÇ –í—á–∏—Ç—É–≤–∞—ö–µ –Ω–∞ cleaned –ø–æ–¥–∞—Ç–æ—Ü–∏...")

        if self.data_dir is None:
            print("‚ùå –ù–µ–º–∞ –≤–∞–ª–∏–¥–Ω–∞ –ø–∞—Ç–µ–∫–∞ –¥–æ –ø–æ–¥–∞—Ç–æ—Ü–∏!")
            return False

        print(f"üîç –ö–æ—Ä–∏—Å—Ç–∞–º –ø–∞–ø–∫–∞: {self.data_dir}")

        if not self.data_dir.exists():
            print(f"‚ùå –ü–∞–ø–∫–∞—Ç–∞ –Ω–µ –ø–æ—Å—Ç–æ–∏: {self.data_dir}")
            return False

        # FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–æ –±–∞—Ä–∞—ö–µ –Ω–∞ —Ñ–∞—ò–ª–æ–≤–∏
        print("üìÅ –°–æ–¥—Ä–∂–∏–Ω–∞ –Ω–∞ –ø–∞–ø–∫–∞—Ç–∞:")
        files_found = []
        for item in self.data_dir.iterdir():
            print(f"   - {item.name}")
            if item.is_file() and item.suffix == '.csv':
                files_found.append(item)

        if not files_found:
            print("‚ùå –ù–µ–º–∞ CSV —Ñ–∞—ò–ª–æ–≤–∏ –≤–æ –ø–∞–ø–∫–∞—Ç–∞!")
            return False

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ —Ñ–∞—ò–ª–æ–≤–∏
        file_priorities = [
            "events_gnn_ready.csv",
            "events_cleaned_",  # –å–µ –∑–µ–º–µ –±–∏–ª–æ –∫–æ—ò —à—Ç–æ –ø–æ—á–Ω—É–≤–∞ —Å–æ –æ–≤–∞
            ".csv"  # –ë–∏–ª–æ –∫–æ—ò CSV
        ]

        selected_file = None
        for priority in file_priorities:
            for file in files_found:
                if priority in file.name:
                    selected_file = file
                    break
            if selected_file:
                break

        if not selected_file:
            # –ó–µ–º–∏ –≥–æ –ø—Ä–≤–∏–æ—Ç CSV —Ñ–∞—ò–ª
            selected_file = files_found[0]

        print(f"üìÑ –ö–æ—Ä–∏—Å—Ç–∞–º —Ñ–∞—ò–ª: {selected_file.name}")

        try:
            # FIXED: –ü—Ä–æ–±–∞—ò —Ä–∞–∑–ª–∏—á–Ω–∏ encoding –æ–ø—Ü–∏–∏
            encodings = ['utf-8-sig', 'utf-8', 'latin-1', 'cp1252']

            for encoding in encodings:
                try:
                    self.df = pd.read_csv(selected_file, encoding=encoding)
                    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –≤—á–∏—Ç–∞–Ω–æ —Å–æ {encoding} encoding")
                    break
                except UnicodeDecodeError:
                    print(f"   ‚ùå {encoding} –Ω–µ —Ä–∞–±–æ—Ç–∏, –ø—Ä–æ–±—É–≤–∞–º —Å–ª–µ–¥–µ–Ω...")
                    continue
            else:
                print("‚ùå –ù–µ –º–æ–∂–∞–º –¥–∞ –≥–æ –ø—Ä–æ—á–∏—Ç–∞–º —Ñ–∞—ò–ª–æ—Ç —Å–æ –Ω–∏–µ–¥–µ–Ω encoding!")
                return False

            print(f"‚úÖ –í—á–∏—Ç–∞–Ω–∏ {len(self.df):,} –∑–∞–ø–∏—Å–∏")
            print(f"üìä –ö–æ–ª–æ–Ω–∏ ({len(self.df.columns)}): {list(self.df.columns)}")

            # –ü—Ä–∏–∫–∞–∂–∏ –ø—Ä–≤–∏—Ç–µ –Ω–µ–∫–æ–ª–∫—É –∑–∞–ø–∏—Å–∏
            print(f"üìã –ü—Ä–∏–º–µ—Ä–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏:")
            print(self.df.head(2).to_string())

            return True

        except Exception as e:
            print(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –≤—á–∏—Ç—É–≤–∞—ö–µ: {e}")
            return False

    def prepare_features(self):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ features"""
        print("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ features...")

        # –ö—Ä–µ–∏—Ä–∞—ò —É–Ω–∏–∫–∞—Ç–Ω–∏ ID-—ò–∞
        if 'node_id' not in self.df.columns:
            self.df['node_id'] = range(len(self.df))

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ—Ç—Ä–µ–±–Ω–∏ –∫–æ–ª–æ–Ω–∏
        required_cols = ['title', 'description']
        missing_cols = [col for col in required_cols if col not in self.df.columns]

        if missing_cols:
            print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Å—É–≤–∞–∞—Ç –∫–æ–ª–æ–Ω–∏: {missing_cols}")
            # –ö—Ä–µ–∏—Ä–∞—ò –ø—Ä–∞–∑–Ω–∏ –∫–æ–ª–æ–Ω–∏
            for col in missing_cols:
                self.df[col] = ''

        # –ü–æ–¥–≥–æ—Ç–≤–∏ features
        try:
            self.prepare_text_features()
            self.prepare_categorical_features()
            self.prepare_numerical_features()
            print(f"‚úÖ Features –ø–æ–¥–≥–æ—Ç–≤–µ–Ω–∏ –∑–∞ {len(self.df)} –Ω–∞—Å—Ç–∞–Ω–∏")
            return True
        except Exception as e:
            print(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ features: {e}")
            return False

    def prepare_text_features(self):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ TF-IDF –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        print("   üìù TF-IDF features...")

        # FIXED: –ü—Ä–∞–≤–∏–ª–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–∞—ö–µ –Ω–∞ pandas –∫–æ–ª–æ–Ω–∏
        combined_parts = []

        for col in ['title', 'description', 'category']:
            if col in self.df.columns:
                cleaned_col = self.df[col].fillna('').astype(str)
                combined_parts.append(cleaned_col)

        if not combined_parts:
            print("   ‚ö†Ô∏è –ù–µ–º–∞ —Ç–µ–∫—Å—Ç—É–∞–ª–Ω–∏ –∫–æ–ª–æ–Ω–∏, –∫–æ—Ä–∏—Å—Ç–∞–º dummy features")
            self.tfidf_features = np.ones((len(self.df), 10))  # Dummy features
            self.feature_names = [f"dummy_feature_{i}" for i in range(10)]
            return

        # FIXED: –ö–æ—Ä–∏—Å—Ç–∏ pandas –∑–∞ –∫–æ–º–±–∏–Ω–∏—Ä–∞—ö–µ –Ω–∞–º–µ—Å—Ç–æ join()
        if len(combined_parts) == 1:
            self.df['combined_text'] = combined_parts[0].str.strip()
        else:
            # –ö–æ–º–±–∏–Ω–∏—Ä–∞—ò –≥–∏ –∫–æ–ª–æ–Ω–∏—Ç–µ —Å–æ space
            self.df['combined_text'] = combined_parts[0]
            for part in combined_parts[1:]:
                self.df['combined_text'] = self.df['combined_text'] + ' ' + part
            self.df['combined_text'] = self.df['combined_text'].str.strip()

        # –§–∏–ª—Ç—Ä–∏—Ä–∞—ò –ø—Ä–∞–∑–Ω–∏ —Ç–µ–∫—Å—Ç–æ–≤–∏
        non_empty_mask = self.df['combined_text'].str.len() > 0
        if non_empty_mask.sum() == 0:
            print("   ‚ö†Ô∏è –°–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–∏ —Å–µ –ø—Ä–∞–∑–Ω–∏, –∫–æ—Ä–∏—Å—Ç–∞–º dummy features")
            self.tfidf_features = np.ones((len(self.df), 10))
            self.feature_names = [f"dummy_feature_{i}" for i in range(10)]
            return

        try:
            # TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—ò–∞
            vectorizer = TfidfVectorizer(
                max_features=50,  # –ù–∞–º–∞–ª–µ–Ω–æ –∑–∞ –ø–æ–º–∞–ª–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ—Å—Ç
                stop_words='english',
                ngram_range=(1, 2),
                min_df=1,  # –ù–∞–º–∞–ª–µ–Ω–æ –∑–∞ –º–∞–ª–∏ dataset-–∏
                token_pattern=r'\b[a-zA-Z]{2,}\b'  # –°–∞–º–æ –±—É–∫–≤–∏, –º–∏–Ω 2 –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏
            )

            tfidf_matrix = vectorizer.fit_transform(self.df['combined_text'])
            self.tfidf_features = tfidf_matrix.toarray()
            self.feature_names = vectorizer.get_feature_names_out()

            print(f"      ‚úÖ TF-IDF: {self.tfidf_features.shape}")

        except Exception as e:
            print(f"   ‚ö†Ô∏è TF-IDF –≥—Ä–µ—à–∫–∞: {e}, –∫–æ—Ä–∏—Å—Ç–∞–º dummy features")
            self.tfidf_features = np.ones((len(self.df), 10))
            self.feature_names = [f"dummy_feature_{i}" for i in range(10)]

        # –§–∏–ª—Ç—Ä–∏—Ä–∞—ò –ø—Ä–∞–∑–Ω–∏ —Ç–µ–∫—Å—Ç–æ–≤–∏
        non_empty_mask = self.df['combined_text'].str.len() > 0
        if non_empty_mask.sum() == 0:
            print("   ‚ö†Ô∏è –°–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–∏ —Å–µ –ø—Ä–∞–∑–Ω–∏, –∫–æ—Ä–∏—Å—Ç–∞–º dummy features")
            self.tfidf_features = np.ones((len(self.df), 10))
            self.feature_names = [f"dummy_feature_{i}" for i in range(10)]
            return

        try:
            # TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—ò–∞
            vectorizer = TfidfVectorizer(
                max_features=50,  # –ù–∞–º–∞–ª–µ–Ω–æ –∑–∞ –ø–æ–º–∞–ª–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ—Å—Ç
                stop_words='english',
                ngram_range=(1, 2),
                min_df=1,  # –ù–∞–º–∞–ª–µ–Ω–æ –∑–∞ –º–∞–ª–∏ dataset-–∏
                token_pattern=r'\b[a-zA-Z]{2,}\b'  # –°–∞–º–æ –±—É–∫–≤–∏, –º–∏–Ω 2 –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏
            )

            tfidf_matrix = vectorizer.fit_transform(self.df['combined_text'])
            self.tfidf_features = tfidf_matrix.toarray()
            self.feature_names = vectorizer.get_feature_names_out()

            print(f"      ‚úÖ TF-IDF: {self.tfidf_features.shape}")

        except Exception as e:
            print(f"   ‚ö†Ô∏è TF-IDF –≥—Ä–µ—à–∫–∞: {e}, –∫–æ—Ä–∏—Å—Ç–∞–º dummy features")
            self.tfidf_features = np.ones((len(self.df), 10))
            self.feature_names = [f"dummy_feature_{i}" for i in range(10)]

    def prepare_categorical_features(self):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—á–∫–∏ features"""
        print("   üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏—á–∫–∏ features...")

        categorical_cols = ['category', 'organizer', 'location', 'source']
        available_cols = [col for col in categorical_cols if col in self.df.columns]

        if not available_cols:
            print("   ‚ö†Ô∏è –ù–µ–º–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—á–∫–∏ –∫–æ–ª–æ–Ω–∏, –∫–æ—Ä–∏—Å—Ç–∞–º dummy features")
            self.categorical_features = np.zeros((len(self.df), 1))
            return

        self.categorical_features = []

        for col in available_cols:
            try:
                # –§–∏–ª—Ç—Ä–∏—Ä–∞—ò NaN –∏ –ø—Ä–∞–∑–Ω–∏ –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏
                cleaned_col = self.df[col].fillna('Unknown').astype(str)
                cleaned_col = cleaned_col.replace('', 'Unknown')

                le = LabelEncoder()
                encoded = le.fit_transform(cleaned_col)
                self.categorical_features.append(encoded)
                self.label_encoders[col] = le
                print(f"      ‚úÖ {col}: {len(le.classes_)} —É–Ω–∏–∫–∞—Ç–Ω–∏ –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏")

            except Exception as e:
                print(f"      ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º —Å–æ {col}: {e}")

        if self.categorical_features:
            self.categorical_features = np.column_stack(self.categorical_features)
            print(f"      ‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—á–∫–∏: {self.categorical_features.shape}")
        else:
            self.categorical_features = np.zeros((len(self.df), 1))

    def prepare_numerical_features(self):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –Ω—É–º–µ—Ä–∏—á–∫–∏ features"""
        print("   üî¢ –ù—É–º–µ—Ä–∏—á–∫–∏ features...")

        numerical_features = []

        # –û—Å–Ω–æ–≤–Ω–∏ features —à—Ç–æ —Å–µ–∫–æ–≥–∞—à –ø–æ—Å—Ç–æ—ò–∞—Ç
        # 1. –î–æ–ª–∂–∏–Ω–∞ –Ω–∞ –Ω–∞—Å–ª–æ–≤
        if 'title' in self.df.columns:
            title_lengths = self.df['title'].fillna('').astype(str).str.len()
            numerical_features.append(title_lengths)

        # 2. –î–æ–ª–∂–∏–Ω–∞ –Ω–∞ –æ–ø–∏—Å
        if 'description' in self.df.columns:
            desc_lengths = self.df['description'].fillna('').astype(str).str.len()
            numerical_features.append(desc_lengths)

        # 3. –î–∞–ª–∏ –µ –±–µ—Å–ø–ª–∞—Ç–µ–Ω (–∞–∫–æ –ø–æ—Å—Ç–æ–∏)
        if 'is_free' in self.df.columns:
            is_free = pd.to_numeric(self.df['is_free'], errors='coerce').fillna(0)
            numerical_features.append(is_free)
        else:
            # Default: —Å–µ —Å–º–µ—Ç–∞–∞—Ç –∫–∞–∫–æ –ø–ª–∞—Ç–µ–Ω–∏
            numerical_features.append(np.zeros(len(self.df)))

        # 4. –î–∞–ª–∏ –∏–º–∞ –¥–∞—Ç–∞ (–∞–∫–æ –ø–æ—Å—Ç–æ–∏)
        if 'date_start' in self.df.columns:
            has_valid_date = ~self.df['date_start'].isin(['–ù–µ —Å–µ –∑–Ω–∞–µ —Å–µ—É—à—Ç–µ', '', 'TBD', None])
            numerical_features.append(has_valid_date.astype(int))
        else:
            numerical_features.append(np.zeros(len(self.df)))

        # 5. –ë—Ä–æ—ò –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏ –≤–æ –∫–æ–º–±–∏–Ω–∏—Ä–∞–Ω —Ç–µ–∫—Å—Ç
        if hasattr(self, 'df') and 'combined_text' in self.df.columns:
            combined_lengths = self.df['combined_text'].str.len()
            numerical_features.append(combined_lengths)

        if numerical_features:
            self.numerical_features = np.column_stack(numerical_features)

            # FIXED: –°–ø—Ä–∞–≤—É–≤–∞—ö–µ —Å–æ inf –∏ NaN –≤—Ä–µ–¥–Ω–æ—Å—Ç–∏
            self.numerical_features = np.nan_to_num(self.numerical_features,
                                                    nan=0.0, posinf=1.0, neginf=0.0)

            # –°—Ç–∞–Ω–¥–∞—Ä–¥–∏–∑–∏—Ä–∞—ò
            try:
                self.numerical_features = self.scaler.fit_transform(self.numerical_features)
                print(f"      ‚úÖ –ù—É–º–µ—Ä–∏—á–∫–∏: {self.numerical_features.shape}")
            except Exception as e:
                print(f"      ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä–¥–∏–∑–∞—Ü–∏—ò–∞: {e}")
                # Fallback: –Ω–æ—Ä–º–∞–ª–∏–∑–∏—Ä–∞—ò —Ä–∞—á–Ω–æ
                for i in range(self.numerical_features.shape[1]):
                    col = self.numerical_features[:, i]
                    if col.std() > 0:
                        self.numerical_features[:, i] = (col - col.mean()) / col.std()
        else:
            self.numerical_features = np.zeros((len(self.df), 1))

    def create_event_similarity_graph(self, similarity_threshold=0.1):  # FIXED: –ù–∞–º–∞–ª–µ–Ω threshold
        """FIXED: –ö—Ä–µ–∏—Ä–∞—ò Event Similarity Graph —Å–æ –ø–æ–¥–æ–±—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        print(f"üîó –ö—Ä–µ–∏—Ä–∞—ö–µ Event Similarity Graph (threshold={similarity_threshold})...")

        try:
            # –ü—Ä–µ—Å–º–µ—Ç–∞—ò TF-IDF —Å–ª–∏—á–Ω–æ—Å—Ç
            if self.tfidf_features.shape[1] > 1:
                similarity_matrix = cosine_similarity(self.tfidf_features)
            else:
                # Fallback: random similarity matrix
                similarity_matrix = np.random.rand(len(self.df), len(self.df))
                np.fill_diagonal(similarity_matrix, 1.0)

            # –ö—Ä–µ–∏—Ä–∞—ò NetworkX –≥—Ä–∞—Ñ
            G = nx.Graph()

            # –î–æ–¥–∞—ò nodes —Å–æ features
            for idx, row in self.df.iterrows():
                node_attrs = {
                    'title': str(row.get('title', f'Event_{idx}')),
                    'node_id': idx
                }

                # –î–æ–¥–∞—ò –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ –∞—Ç—Ä–∏–±—É—Ç–∏ –∞–∫–æ –ø–æ—Å—Ç–æ—ò–∞—Ç
                for attr in ['category', 'organizer', 'location']:
                    if attr in row:
                        node_attrs[attr] = str(row[attr]) if pd.notna(row[attr]) else 'Unknown'

                G.add_node(idx, **node_attrs)

            # –î–æ–¥–∞—ò edges –≤—Ä–∑ –æ—Å–Ω–æ–≤–∞ –Ω–∞ —Å–ª–∏—á–Ω–æ—Å—Ç
            edges_added = 0
            for i in range(len(self.df)):
                for j in range(i + 1, len(self.df)):
                    similarity = similarity_matrix[i][j]
                    if similarity > similarity_threshold:
                        G.add_edge(i, j, weight=float(similarity), edge_type='similarity')
                        edges_added += 1

            print(f"   ‚úÖ {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")

            # –ê–∫–æ –Ω–µ–º–∞ –¥–æ–≤–æ–ª–Ω–æ edges, –Ω–∞–º–∞–ª–∏ –≥–æ threshold
            if G.number_of_edges() < 10 and similarity_threshold > 0.05:
                print(f"   ‚ö†Ô∏è –ú–∞–ª–∫—É edges ({G.number_of_edges()}), –ø—Ä–æ–±—É–≤–∞–º —Å–æ threshold=0.05")
                return self.create_event_similarity_graph(similarity_threshold=0.05)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞—ò –≤–æ PyTorch Geometric
            if G.number_of_edges() > 0:
                data = from_networkx(G)
            else:
                # –ö—Ä–µ–∏—Ä–∞—ò –ø—Ä–∞–∑–µ–Ω –≥—Ä–∞—Ñ
                print("   ‚ö†Ô∏è –ù–µ–º–∞ edges, –∫—Ä–µ–∏—Ä–∞–º –ø—Ä–∞–∑–µ–Ω –≥—Ä–∞—Ñ")
                data = Data()
                data.num_nodes = len(self.df)
                data.edge_index = torch.zeros((2, 0), dtype=torch.long)

            # –î–æ–¥–∞—ò node features
            all_features = np.concatenate([
                self.tfidf_features,
                self.categorical_features,
                self.numerical_features
            ], axis=1)

            data.x = torch.tensor(all_features, dtype=torch.float)
            data.num_nodes = len(self.df)

            self.graphs['event_similarity'] = data
            self.stats['event_similarity'] = {
                'nodes': G.number_of_nodes(),
                'edges': G.number_of_edges(),
                'density': nx.density(G) if G.number_of_edges() > 0 else 0.0,
                'avg_degree': sum(dict(G.degree()).values()) / G.number_of_nodes() if G.number_of_nodes() > 0 else 0
            }

            return G, data

        except Exception as e:
            print(f"   ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∫—Ä–µ–∏—Ä–∞—ö–µ similarity –≥—Ä–∞—Ñ: {e}")
            return None, None

    def create_heterogeneous_graph(self):
        """FIXED: –ö—Ä–µ–∏—Ä–∞—ò Heterogeneous Graph —Å–æ –ø–æ–¥–æ–±—Ä–∞ error handling"""
        print("üåê –ö—Ä–µ–∏—Ä–∞—ö–µ Heterogeneous Graph...")

        try:
            hetero_data = HeteroData()

            # EVENT NODES
            all_features = np.concatenate([
                self.tfidf_features,
                self.categorical_features,
                self.numerical_features
            ], axis=1)

            hetero_data['event'].x = torch.tensor(all_features, dtype=torch.float)
            hetero_data['event'].num_nodes = len(self.df)

            # ORGANIZER NODES
            if 'organizer' in self.df.columns:
                organizers = self.df['organizer'].dropna().unique()
                organizers = [str(org) for org in organizers if str(org) != 'nan']
            else:
                organizers = ['Unknown_Organizer']

            organizer_to_idx = {org: idx for idx, org in enumerate(organizers)}

            # Organizer features
            organizer_features = []
            for org in organizers:
                if 'organizer' in self.df.columns:
                    org_events = self.df[self.df['organizer'].astype(str) == org]
                else:
                    org_events = self.df  # Fallback

                features = [
                    len(org_events),  # –ë—Ä–æ—ò –Ω–∞—Å—Ç–∞–Ω–∏
                    org_events.get('is_free', pd.Series([0])).mean(),  # % –±–µ—Å–ø–ª–∞—Ç–Ω–∏
                    len(org_events.get('category', pd.Series(['Unknown'])).unique())  # –ë—Ä–æ—ò –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                ]
                organizer_features.append(features)

            hetero_data['organizer'].x = torch.tensor(organizer_features, dtype=torch.float)
            hetero_data['organizer'].num_nodes = len(organizers)

            # VENUE NODES
            if 'location' in self.df.columns:
                venues = self.df['location'].dropna().unique()
                venues = [str(venue) for venue in venues if str(venue) != 'nan']
            else:
                venues = ['Unknown_Venue']

            venue_to_idx = {venue: idx for idx, venue in enumerate(venues)}

            # Venue features
            venue_features = []
            for venue in venues:
                if 'location' in self.df.columns:
                    venue_events = self.df[self.df['location'].astype(str) == venue]
                else:
                    venue_events = self.df  # Fallback

                features = [
                    len(venue_events),  # –ë—Ä–æ—ò –Ω–∞—Å—Ç–∞–Ω–∏
                    len(venue_events.get('category', pd.Series(['Unknown'])).unique()),  # –ë—Ä–æ—ò –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    venue_events.get('is_free', pd.Series([0])).mean()  # % –±–µ—Å–ø–ª–∞—Ç–Ω–∏
                ]
                venue_features.append(features)

            hetero_data['venue'].x = torch.tensor(venue_features, dtype=torch.float)
            hetero_data['venue'].num_nodes = len(venues)

            # EDGES: Event -> Organizer
            event_org_edges = []
            if 'organizer' in self.df.columns:
                for idx, row in self.df.iterrows():
                    org = str(row.get('organizer', ''))
                    if org in organizer_to_idx:
                        org_idx = organizer_to_idx[org]
                        event_org_edges.append([idx, org_idx])

            if event_org_edges:
                hetero_data['event', 'organized_by', 'organizer'].edge_index = \
                    torch.tensor(event_org_edges, dtype=torch.long).t().contiguous()

            # EDGES: Event -> Venue
            event_venue_edges = []
            if 'location' in self.df.columns:
                for idx, row in self.df.iterrows():
                    venue = str(row.get('location', ''))
                    if venue in venue_to_idx:
                        venue_idx = venue_to_idx[venue]
                        event_venue_edges.append([idx, venue_idx])

            if event_venue_edges:
                hetero_data['event', 'located_at', 'venue'].edge_index = \
                    torch.tensor(event_venue_edges, dtype=torch.long).t().contiguous()

            print(f"   ‚úÖ Events: {hetero_data['event'].num_nodes}")
            print(f"   ‚úÖ Organizers: {hetero_data['organizer'].num_nodes}")
            print(f"   ‚úÖ Venues: {hetero_data['venue'].num_nodes}")

            self.graphs['heterogeneous'] = hetero_data
            self.stats['heterogeneous'] = {
                'event_nodes': hetero_data['event'].num_nodes,
                'organizer_nodes': hetero_data['organizer'].num_nodes,
                'venue_nodes': hetero_data['venue'].num_nodes,
                'event_org_edges': len(event_org_edges),
                'event_venue_edges': len(event_venue_edges)
            }

            return hetero_data

        except Exception as e:
            print(f"   ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∫—Ä–µ–∏—Ä–∞—ö–µ heterogeneous –≥—Ä–∞—Ñ: {e}")
            return None

    def visualize_graphs(self):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞ —Å–æ error handling"""
        print("üé® –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞ –Ω–∞ –≥—Ä–∞—Ñ–æ–≤–∏...")

        vis_dir = self.output_dir / "visualizations"
        vis_dir.mkdir(exist_ok=True)

        try:
            # 1. Event Similarity Graph
            if 'event_similarity' in self.graphs:
                self.visualize_similarity_graph(vis_dir)

            # 2. Heterogeneous Graph Overview
            if 'heterogeneous' in self.graphs:
                self.visualize_hetero_overview(vis_dir)

            # 3. Graph Statistics
            self.visualize_graph_stats(vis_dir)

            print(f"   ‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞—á—É–≤–∞–Ω–∏ –≤–æ: {vis_dir}")

        except Exception as e:
            print(f"   ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º —Å–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞: {e}")

    def visualize_similarity_graph(self, vis_dir):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞ –Ω–∞ similarity –≥—Ä–∞—Ñ"""
        try:
            data = self.graphs['event_similarity']

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞—ò –Ω–∞–∑–∞–¥ –≤–æ NetworkX –∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞
            if hasattr(data, 'edge_index') and data.edge_index.shape[1] > 0:
                G = to_networkx(data, to_undirected=True)
            else:
                # –ö—Ä–µ–∏—Ä–∞—ò –≥—Ä–∞—Ñ —Å–∞–º–æ —Å–æ nodes
                G = nx.Graph()
                for i in range(len(self.df)):
                    title = self.df.iloc[i].get('title', f'Event_{i}')
                    G.add_node(i, title=str(title)[:20])

            # –ó–µ–º–∏ subset –∑–∞ visualization (–∞–∫–æ –µ –ø—Ä–µ–º–Ω–æ–≥—É –≥–æ–ª–µ–º)
            if G.number_of_nodes() > 100:
                degrees = dict(G.degree())
                top_nodes = sorted(degrees.items(), key=lambda x: x[1], reverse=True)[:50]
                subgraph_nodes = [node for node, degree in top_nodes]
                G = G.subgraph(subgraph_nodes)

            plt.figure(figsize=(12, 8))

            # Layout
            if G.number_of_edges() > 0:
                pos = nx.spring_layout(G, k=2, iterations=30)
            else:
                # Random layout –∑–∞ nodes –±–µ–∑ edges
                pos = {node: (np.random.rand(), np.random.rand()) for node in G.nodes()}

            # Node colors –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—ò–∞
            if 'category' in self.df.columns:
                categories = []
                for node in G.nodes():
                    if node < len(self.df):
                        cat = self.df.iloc[node].get('category', 'Unknown')
                        categories.append(str(cat) if pd.notna(cat) else 'Unknown')
                    else:
                        categories.append('Unknown')
            else:
                categories = ['Unknown'] * len(G.nodes())

            unique_categories = list(set(categories))
            colors = plt.cm.Set3(np.linspace(0, 1, len(unique_categories)))
            color_map = dict(zip(unique_categories, colors))
            node_colors = [color_map[cat] for cat in categories]

            # –¶—Ä—Ç–∞—ò –≥—Ä–∞—Ñ
            nx.draw_networkx_nodes(G, pos, node_color=node_colors,
                                   node_size=100, alpha=0.8)

            if G.number_of_edges() > 0:
                nx.draw_networkx_edges(G, pos, alpha=0.3, width=0.5)

            # –õ–µ–≥–µ–Ω–¥–∞
            for cat, color in color_map.items():
                plt.scatter([], [], c=[color], label=cat[:15], s=100)

            plt.legend(title="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.title("üîó Event Similarity Graph", size=14, fontweight='bold')
            plt.axis('off')
            plt.tight_layout()
            plt.savefig(vis_dir / 'similarity_graph.png', dpi=200, bbox_inches='tight')
            plt.close()  # FIXED: –ó–∞—Ç–≤–æ—Ä–∏ —ò–∞ —Ñ–∏–≥—É—Ä–∞—Ç–∞

        except Exception as e:
            print(f"      ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º —Å–æ similarity visualization: {e}")

    def visualize_hetero_overview(self, vis_dir):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ visualizacija –Ω–∞ heterogeneous –≥—Ä–∞—Ñ"""
        try:
            hetero_data = self.graphs['heterogeneous']

            fig, axes = plt.subplots(2, 2, figsize=(14, 10))

            # 1. Node counts
            node_types = ['Events', 'Organizers', 'Venues']
            node_counts = [
                hetero_data['event'].num_nodes,
                hetero_data['organizer'].num_nodes,
                hetero_data['venue'].num_nodes
            ]

            bars = axes[0, 0].bar(node_types, node_counts, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
            axes[0, 0].set_title('üåê Node Types', fontweight='bold')
            axes[0, 0].set_ylabel('–ë—Ä–æ—ò nodes')

            for bar, count in zip(bars, node_counts):
                axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(node_counts) * 0.01,
                                str(count), ha='center', va='bottom', fontweight='bold')

            # 2. Edge types
            edge_types = ['Event‚ÜíOrganizer', 'Event‚ÜíVenue']
            edge_counts = [
                self.stats['heterogeneous']['event_org_edges'],
                self.stats['heterogeneous']['event_venue_edges']
            ]

            bars = axes[0, 1].bar(edge_types, edge_counts, color=['#d62728', '#9467bd'])
            axes[0, 1].set_title('üîó Edge Types', fontweight='bold')
            axes[0, 1].set_ylabel('–ë—Ä–æ—ò edges')
            axes[0, 1].tick_params(axis='x', rotation=15)

            for bar, count in zip(bars, edge_counts):
                axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(edge_counts) * 0.01,
                                str(count), ha='center', va='bottom', fontweight='bold')

            # 3. Organizer distribution
            if 'organizer' in self.df.columns:
                organizer_event_counts = self.df['organizer'].value_counts().head(10)
            else:
                organizer_event_counts = pd.Series(['Unknown'], index=['Unknown_Organizer'])

            y_pos = range(len(organizer_event_counts))
            axes[1, 0].barh(y_pos, organizer_event_counts.values)
            axes[1, 0].set_yticks(y_pos)
            axes[1, 0].set_yticklabels([org[:15] + '...' if len(str(org)) > 15 else str(org)
                                        for org in organizer_event_counts.index])
            axes[1, 0].set_title('üè¢ Top Organizers', fontweight='bold')
            axes[1, 0].set_xlabel('–ë—Ä–æ—ò –Ω–∞—Å—Ç–∞–Ω–∏')
            axes[1, 0].invert_yaxis()

            # 4. Venue distribution
            if 'location' in self.df.columns:
                venue_event_counts = self.df['location'].value_counts().head(10)
            else:
                venue_event_counts = pd.Series([len(self.df)], index=['Unknown_Venue'])

            y_pos = range(len(venue_event_counts))
            axes[1, 1].barh(y_pos, venue_event_counts.values)
            axes[1, 1].set_yticks(y_pos)
            axes[1, 1].set_yticklabels([venue[:15] + '...' if len(str(venue)) > 15 else str(venue)
                                        for venue in venue_event_counts.index])
            axes[1, 1].set_title('üèõÔ∏è Top Venues', fontweight='bold')
            axes[1, 1].set_xlabel('–ë—Ä–æ—ò –Ω–∞—Å—Ç–∞–Ω–∏')
            axes[1, 1].invert_yaxis()

            plt.tight_layout()
            plt.savefig(vis_dir / 'heterogeneous_overview.png', dpi=200, bbox_inches='tight')
            plt.close()  # FIXED: –ó–∞—Ç–≤–æ—Ä–∏ —ò–∞ —Ñ–∏–≥—É—Ä–∞—Ç–∞

        except Exception as e:
            print(f"      ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º —Å–æ hetero visualization: {e}")

    def visualize_graph_stats(self, vis_dir):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—ò–∞"""
        if not self.stats:
            return

        try:
            fig, axes = plt.subplots(2, 2, figsize=(14, 8))

            # 1. Node counts comparison
            graph_names = list(self.stats.keys())
            node_counts = []

            for graph_name in graph_names:
                if graph_name == 'heterogeneous':
                    node_counts.append(self.stats[graph_name]['event_nodes'])
                else:
                    node_counts.append(self.stats[graph_name]['nodes'])

            bars = axes[0, 0].bar(graph_names, node_counts, alpha=0.8)
            axes[0, 0].set_title('üìä Nodes –ø–æ —Ç–∏–ø –≥—Ä–∞—Ñ', fontweight='bold')
            axes[0, 0].set_ylabel('–ë—Ä–æ—ò nodes')
            axes[0, 0].tick_params(axis='x', rotation=15)

            for bar, count in zip(bars, node_counts):
                axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(node_counts) * 0.01,
                                str(count), ha='center', va='bottom', fontweight='bold')

            # 2. Edge counts comparison
            edge_counts = []
            for graph_name in graph_names:
                if graph_name == 'heterogeneous':
                    total_edges = (self.stats[graph_name]['event_org_edges'] +
                                   self.stats[graph_name]['event_venue_edges'])
                    edge_counts.append(total_edges)
                else:
                    edge_counts.append(self.stats[graph_name]['edges'])

            bars = axes[0, 1].bar(graph_names, edge_counts, alpha=0.8, color='orange')
            axes[0, 1].set_title('üîó Edges –ø–æ —Ç–∏–ø –≥—Ä–∞—Ñ', fontweight='bold')
            axes[0, 1].set_ylabel('–ë—Ä–æ—ò edges')
            axes[0, 1].tick_params(axis='x', rotation=15)

            for bar, count in zip(bars, edge_counts):
                axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(edge_counts) * 0.01,
                                str(count), ha='center', va='bottom', fontweight='bold')

            # 3. Feature dimensions
            feature_info = {
                'TF-IDF': self.tfidf_features.shape[1],
                'Categorical': self.categorical_features.shape[1],
                'Numerical': self.numerical_features.shape[1]
            }

            bars = axes[1, 0].bar(feature_info.keys(), feature_info.values(),
                                  alpha=0.8, color='purple')
            axes[1, 0].set_title('üéØ Feature Dimensions', fontweight='bold')
            axes[1, 0].set_ylabel('–ë—Ä–æ—ò features')

            for bar, count in zip(bars, feature_info.values()):
                axes[1, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(feature_info.values()) * 0.01,
                                str(count), ha='center', va='bottom', fontweight='bold')

            # 4. Data quality overview
            quality_metrics = {
                'Total Events': len(self.df),
                'With Title': len(self.df[self.df.get('title', pd.Series()).fillna('').astype(str).str.len() > 0]),
                'With Category': len(
                    self.df[self.df.get('category', pd.Series()).notna()]) if 'category' in self.df.columns else 0,
                'With Organizer': len(
                    self.df[self.df.get('organizer', pd.Series()).notna()]) if 'organizer' in self.df.columns else 0
            }

            bars = axes[1, 1].bar(quality_metrics.keys(), quality_metrics.values(),
                                  alpha=0.8, color='green')
            axes[1, 1].set_title('üìã Data Quality', fontweight='bold')
            axes[1, 1].set_ylabel('–ë—Ä–æ—ò –∑–∞–ø–∏—Å–∏')
            axes[1, 1].tick_params(axis='x', rotation=15)

            for bar, count in zip(bars, quality_metrics.values()):
                axes[1, 1].text(bar.get_x() + bar.get_width() / 2,
                                bar.get_height() + max(quality_metrics.values()) * 0.01,
                                str(count), ha='center', va='bottom', fontweight='bold')

            plt.tight_layout()
            plt.savefig(vis_dir / 'graph_statistics.png', dpi=200, bbox_inches='tight')
            plt.close()  # FIXED: –ó–∞—Ç–≤–æ—Ä–∏ —ò–∞ —Ñ–∏–≥—É—Ä–∞—Ç–∞

        except Exception as e:
            print(f"      ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º —Å–æ stats visualization: {e}")

    def save_graphs(self):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–æ –∑–∞—á—É–≤—É–≤–∞—ö–µ —Å–æ error handling"""
        print("üíæ –ó–∞—á—É–≤—É–≤–∞—ö–µ –Ω–∞ –≥—Ä–∞—Ñ–æ–≤–∏...")

        try:
            # PyTorch Geometric —Ñ–æ—Ä–º–∞—Ç
            saved_count = 0
            for name, graph in self.graphs.items():
                try:
                    output_file = self.output_dir / f"{name}_graph.pt"
                    torch.save(graph, output_file)
                    print(f"   ‚úÖ {name}_graph.pt")
                    saved_count += 1
                except Exception as e:
                    print(f"   ‚ùå –ü—Ä–æ–±–ª–µ–º —Å–æ {name}: {e}")

            # –ú–µ—Ç–∞–ø–æ–¥–∞—Ç–æ—Ü–∏
            metadata = {
                'created_at': datetime.now().isoformat(),
                'total_events': len(self.df),
                'graphs_created': list(self.graphs.keys()),
                'feature_dimensions': {
                    'tfidf': int(self.tfidf_features.shape[1]),
                    'categorical': int(self.categorical_features.shape[1]),
                    'numerical': int(self.numerical_features.shape[1])
                },
                'statistics': self.stats,
                'data_columns': list(self.df.columns)
            }

            with open(self.output_dir / 'graph_metadata.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            print(f"   ‚úÖ graph_metadata.json")
            print(f"üíæ {saved_count} –≥—Ä–∞—Ñ–æ–≤–∏ –∑–∞—á—É–≤–∞–Ω–∏ –≤–æ: {self.output_dir}")
            return True

        except Exception as e:
            print(f"‚ùå –ü—Ä–æ–±–ª–µ–º —Å–æ –∑–∞—á—É–≤—É–≤–∞—ö–µ: {e}")
            return False

    def generate_summary(self):
        """FIXED: –ü–æ–¥–æ–±—Ä–µ–Ω–æ —Ä–µ–∑–∏–º–µ —Å–æ error handling"""
        print("\n" + "=" * 60)
        print("üîó GRAPH CONSTRUCTION –†–ï–ó–£–õ–¢–ê–¢–ò")
        print("=" * 60)
        print(f"üìä Dataset: {len(self.df):,} –Ω–∞—Å—Ç–∞–Ω–∏")

        if hasattr(self, 'tfidf_features') and hasattr(self, 'categorical_features') and hasattr(self,
                                                                                                 'numerical_features'):
            total_features = (self.tfidf_features.shape[1] +
                              self.categorical_features.shape[1] +
                              self.numerical_features.shape[1])
            print(f"üéØ Feature dimensions: {total_features}")

        print(f"üìà –ì—Ä–∞—Ñ–æ–≤–∏ —Å–æ–∑–¥–∞–¥–µ–Ω–∏: {len(self.graphs)}")

        for name, stats in self.stats.items():
            print(f"\nüîó {name.title()} Graph:")
            if 'nodes' in stats:
                print(f"   Nodes: {stats['nodes']:,}")
                print(f"   Edges: {stats['edges']:,}")
                print(f"   Density: {stats['density']:.4f}")
                if 'avg_degree' in stats:
                    print(f"   Avg Degree: {stats['avg_degree']:.2f}")
            else:
                for key, value in stats.items():
                    print(f"   {key}: {value}")

        print(f"\nüìÅ Output –ø–∞–ø–∫–∞: {self.output_dir}")
        print("‚úÖ Graph Construction –∑–∞–≤—Ä—à–µ–Ω!")

    def run_full_construction(self):
        """FIXED: –ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞ —Å–æ –ø–æ–¥–æ–±—Ä–µ–Ω error handling"""
        print("üîó Graph Construction System")
        print("=" * 50)

        try:
            # 1. Load data
            if not self.load_data():
                print("‚ùå –ù–µ –º–æ–∂–∞–º –¥–∞ –≥–∏ –≤—á–∏—Ç–∞–º –ø–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ!")
                return False

            # 2. Prepare features
            if not self.prepare_features():
                print("‚ùå –ü—Ä–æ–±–ª–µ–º —Å–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ features!")
                return False

            # 3. Create graphs
            print("\nüî® –ö—Ä–µ–∏—Ä–∞—ö–µ –≥—Ä–∞—Ñ–æ–≤–∏...")
            graphs_created = 0

            # Event Similarity Graph
            try:
                result = self.create_event_similarity_graph()
                if result[0] is not None:
                    graphs_created += 1
                    print("   ‚úÖ Event Similarity Graph")
                else:
                    print("   ‚ö†Ô∏è Event Similarity Graph –Ω–µ –µ –∫—Ä–µ–∏—Ä–∞–Ω")
            except Exception as e:
                print(f"   ‚ùå Similarity graph: {e}")

            # Heterogeneous Graph
            try:
                hetero_result = self.create_heterogeneous_graph()
                if hetero_result is not None:
                    graphs_created += 1
                    print("   ‚úÖ Heterogeneous Graph")
                else:
                    print("   ‚ö†Ô∏è Heterogeneous Graph –Ω–µ –µ –∫—Ä–µ–∏—Ä–∞–Ω")
            except Exception as e:
                print(f"   ‚ùå Heterogeneous graph: {e}")

            if graphs_created == 0:
                print("‚ùå –ù–∏–µ–¥–µ–Ω –≥—Ä–∞—Ñ –Ω–µ –µ –∫—Ä–µ–∏—Ä–∞–Ω!")
                return False

            # 4. Visualize
            self.visualize_graphs()

            # 5. Save
            if not self.save_graphs():
                print("‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º —Å–æ –∑–∞—á—É–≤—É–≤–∞—ö–µ, –Ω–æ –≥—Ä–∞—Ñ–æ–≤–∏—Ç–µ —Å–µ –∫—Ä–µ–∏—Ä–∞–Ω–∏")

            # 6. Summary
            self.generate_summary()

            return True

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –≥—Ä–µ—à–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """FIXED: –ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞ —Å–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∞ –¥–µ—Ç–µ–∫—Ü–∏—ò–∞"""
    try:
        print("üîó Graph Construction System - FIXED VERSION")
        print("=" * 50)

        # –ö—Ä–µ–∏—Ä–∞—ò –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä (–∞–≤—Ç–æ–º–∞—Ç—Å–∫–∏ —ú–µ –≥–∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä–∞ –ø–∞—Ç–∏—à—Ç–∞—Ç–∞)
        constructor = GraphConstructor()

        if constructor.data_dir is None:
            print("\n‚ùå –ù–µ –º–æ–∂–∞–º –¥–∞ –Ω–∞—ò–¥–∞–º cleaned_data!")
            print("üìã –ü—Ä–µ–¥–ª–æ–∑–∏:")
            print("   1. –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ –ø–æ—Å—Ç–æ–∏ –ø–∞–ø–∫–∞—Ç–∞ 'data_collection/NLP_data/cleaned_data/'")
            print("   2. –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ –∏–º–∞ CSV —Ñ–∞—ò–ª–æ–≤–∏ –≤–æ —Ç–∞–∞ –ø–∞–ø–∫–∞")
            print("   3. –°—Ç–∞—Ä—Ç—É–≤–∞—ò —ò–∞ —Å–∫—Ä–∏–ø—Ç–∞—Ç–∞ –æ–¥ root –ø–∞–ø–∫–∞—Ç–∞ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–æ—Ç")
            return False

        success = constructor.run_full_construction()

        if success:
            print("\nüéâ Graph Construction –∑–∞–≤—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"\nüìÇ –ü—Ä–æ–≤–µ—Ä–∏ —ò–∞ –ø–∞–ø–∫–∞—Ç–∞ '{constructor.output_dir}' –∑–∞:")
            print("   - PyTorch Geometric graph —Ñ–∞—ò–ª–æ–≤–∏ (.pt)")
            print("   - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (PNG)")
            print("   - –ú–µ—Ç–∞–ø–æ–¥–∞—Ç–æ—Ü–∏ (JSON)")
            print("\nüí° –°–ª–µ–¥–µ–Ω —á–µ–∫–æ—Ä: –ö–æ—Ä–∏—Å—Ç–∏ –≥–∏ .pt —Ñ–∞—ò–ª–æ–≤–∏—Ç–µ –∑–∞ GNN —Ç—Ä–µ–Ω–∏—Ä–∞—ö–µ!")
        else:
            print("\n‚ùå –ü—Ä–æ–±–ª–µ–º –ø—Ä–∏ graph construction")
            print("üìã –ú–æ–∂–Ω–∏ —Ä–µ—à–µ–Ω–∏—ò–∞:")
            print("   1. –ü—Ä–æ–≤–µ—Ä–∏ –≥–∏ –ø–∞—Ç–∏—à—Ç–∞—Ç–∞ –¥–æ –ø–æ–¥–∞—Ç–æ—Ü–∏—Ç–µ")
            print("   2. –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ CSV —Ñ–∞—ò–ª–æ–≤–∏—Ç–µ —Å–µ —á–∏—Ç–ª–∏–≤–∏")
            print("   3. –ò–Ω—Å—Ç–∞–ª–∏—Ä–∞—ò –≥–∏ –ø–æ—Ç—Ä–µ–±–Ω–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏")

        return success

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –≥—Ä–µ—à–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    main()