#!/usr/bin/env python3

import time
import re
from datetime import datetime
from typing import List, Dict, Optional
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import os
import glob
import hashlib
import logging


class ITEventsScraper:
    """
    –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –≤–µ—Ä–∑–∏—ò–∞ –Ω–∞ —Å–∫—Ä–µ–ø–µ—Ä –∑–∞ IT –Ω–∞—Å—Ç–∞–Ω–∏ –æ–¥ it.mk
    —Å–æ –ø–æ–¥–æ–±—Ä–æ error handling, debugging –∏ –ø–æ—Ä–æ–±—É—Å–Ω–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∏
    """

    def __init__(self, debug=True):
        self.base_url = "https://it.mk"
        self.it_nastan_url = "https://it.mk/tag/it-nastan/"
        self.driver = None
        self.wait = None
        self.debug = debug
        self.raw_data_dir = "../raw_data"
        self.processed_data_dir = "../processed_data"

        # Setup logging
        logging.basicConfig(
            level=logging.INFO if debug else logging.WARNING,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)

        os.makedirs(self.raw_data_dir, exist_ok=True)
        os.makedirs(self.processed_data_dir, exist_ok=True)

    def clean_old_files(self):
        """–û—Ç—Å—Ç—Ä–∞–Ω–∏ —Å—Ç–∞—Ä–∏ —Ñ–∞—ò–ª–æ–≤–∏"""
        old_raw_files = glob.glob(os.path.join(self.raw_data_dir, "it_events_raw_*.csv"))
        old_processed_files = glob.glob(os.path.join(self.processed_data_dir, "it_events_*.csv"))

        for file_path in old_raw_files + old_processed_files:
            os.remove(file_path)
            self.logger.info(f"–û—Ç—Å—Ç—Ä–∞–Ω–µ—Ç —Ñ–∞—ò–ª: {file_path}")

    def setup_driver(self):
        """Setup Chrome driver —Å–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∏ –æ–ø—Ü–∏–∏"""
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-plugins")
        chrome_options.add_argument("--disable-images")  # –ü–æ–±—Ä–∑–æ –≤—á–∏—Ç—É–≤–∞—ö–µ
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument(
            "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )

        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.set_page_load_timeout(30)
            self.wait = WebDriverWait(self.driver, 10)
            self.logger.info("‚úÖ Chrome driver —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç–∞–≤–µ–Ω")
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç–∞–≤—É–≤–∞—ö–µ –Ω–∞ driver: {e}")
            raise

    def close_driver(self):
        """–ó–∞—Ç–≤–æ—Ä–∏ –≥–æ driver-–æ—Ç"""
        if self.driver:
            self.driver.quit()
            self.logger.info("üîí Driver –∑–∞—Ç–≤–æ—Ä–µ–Ω")

    def generate_event_id(self, title: str, date: str = "") -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–∞ —É–Ω–∏–∫–∞—Ç–µ–Ω event_id"""
        clean_title = re.sub(r'[^\w\s]', '', title.lower())
        combined = f"{clean_title}_{date}".strip('_')
        return hashlib.md5(combined.encode()).hexdigest()

    def debug_page_structure(self):
        """Debug —Ñ—É–Ω–∫—Ü–∏—ò–∞ –∑–∞ –¥–∞ —Å–µ –≤–∏–¥–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ç–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞"""
        if not self.debug:
            return

        try:
            self.logger.info("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞...")

            # –°–∏—Ç–µ articles
            all_articles = self.driver.find_elements(By.TAG_NAME, "article")
            self.logger.info(f"üìä –í–∫—É–ø–Ω–æ <article> –µ–ª–µ–º–µ–Ω—Ç–∏: {len(all_articles)}")

            # –ü—Ä–æ–≤–µ—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∏
            selectors_to_test = [
                "article.post.category-it-nastan",
                "article.post",
                "article",
                ".post",
                "[class*='post']",
                "[class*='event']",
                "[class*='nastan']"
            ]

            for selector in selectors_to_test:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                self.logger.info(f"üìã '{selector}': {len(elements)} –µ–ª–µ–º–µ–Ω—Ç–∏")

            # –î–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –ø—Ä–≤–∏—Ç–µ 2 articles
            for i, article in enumerate(all_articles[:2]):
                self.logger.info(f"\n--- Article {i + 1} ---")
                self.logger.info(f"Classes: {article.get_attribute('class')}")

                # –ü—Ä–æ–Ω–∞—ò–¥–∏ –Ω–∞—Å–ª–æ–≤
                title_elements = article.find_elements(By.CSS_SELECTOR,
                                                       "h1, h2, h3, .entry-title, .post-title, [class*='title']")
                for j, title_el in enumerate(title_elements):
                    text = title_el.text.strip()
                    if text:
                        self.logger.info(
                            f"  –ù–∞—Å–ª–æ–≤ {j + 1}: '{text}' (tag: {title_el.tag_name}, class: {title_el.get_attribute('class')})")

                # –ü—Ä–æ–Ω–∞—ò–¥–∏ –ª–∏–Ω–∫–æ–≤–∏
                links = article.find_elements(By.TAG_NAME, "a")
                for j, link in enumerate(links[:3]):  # –ü—Ä–≤–∏—Ç–µ 3 –ª–∏–Ω–∫–∞
                    href = link.get_attribute('href')
                    text = link.text.strip()
                    if href and 'it-nastan' in href:
                        self.logger.info(f"  –õ–∏–Ω–∫ {j + 1}: '{text}' -> {href}")

                self.logger.info(f"  HTML preview: {article.get_attribute('outerHTML')[:200]}...")

        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ debug: {e}")

    def extract_title_robust(self, item) -> str:
        """–†–æ–±—É—Å–Ω–æ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –Ω–∞—Å–ª–æ–≤"""
        title_strategies = [
            # –°—Ç–∞–Ω–¥–∞—Ä–¥–Ω–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∏
            lambda: item.find_element(By.CSS_SELECTOR, ".entry-title").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, ".post-title").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "h1").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "h2").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "h3").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "[class*='title']").text.strip(),

            # –õ–∏–Ω–∫–æ–≤–∏
            lambda: item.find_element(By.CSS_SELECTOR, "a").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "a").get_attribute("title"),

            # –î—Ä—É–≥–∏ –ø—Ä–∏—Å—Ç–∞–ø–∏
            lambda: item.find_element(By.CSS_SELECTOR, ".entry-header").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "header").text.strip(),
        ]

        for i, strategy in enumerate(title_strategies):
            try:
                title = strategy()
                if title and len(title.strip()) > 3:
                    if self.debug:
                        self.logger.debug(f"  ‚úÖ –ù–∞—Å–ª–æ–≤ –Ω–∞—ò–¥–µ–Ω —Å–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—ò–∞ {i + 1}: '{title}'")
                    return title.strip()
            except (NoSuchElementException, Exception):
                continue

        # –ê–∫–æ –Ω–∏—à—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∏, –∑–µ–º–∏ –≥–æ —Ç–µ–∫—Å—Ç–æ—Ç –æ–¥ —Ü–µ–ª–∏–æ—Ç –µ–ª–µ–º–µ–Ω—Ç
        try:
            full_text = item.text.strip()
            if full_text and len(full_text) > 3:
                # –ó–µ–º–∏ —ò–∞ –ø—Ä–≤–∞—Ç–∞ –ª–∏–Ω–∏—ò–∞ –∫–∞–∫–æ –Ω–∞—Å–ª–æ–≤
                first_line = full_text.split('\n')[0].strip()
                if len(first_line) > 3:
                    self.logger.debug(f"  ‚ö†Ô∏è –ö–æ—Ä–∏—Å—Ç–∞–º –ø—Ä–≤–∞ –ª–∏–Ω–∏—ò–∞ –∫–∞–∫–æ –Ω–∞—Å–ª–æ–≤: '{first_line}'")
                    return first_line
        except:
            pass

        return ""

    def extract_url_robust(self, item) -> str:
        """–†–æ–±—É—Å–Ω–æ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ URL"""
        url_strategies = [
            lambda: item.find_element(By.CSS_SELECTOR, 'a[href*="/it-nastan/"]').get_attribute('href'),
            lambda: item.find_element(By.CSS_SELECTOR, 'a[href*="it-nastan"]').get_attribute('href'),
            lambda: item.find_element(By.CSS_SELECTOR, 'a').get_attribute('href'),
        ]

        for strategy in url_strategies:
            try:
                url = strategy()
                if url and 'it-nastan' in url:
                    return url
            except (NoSuchElementException, Exception):
                continue
        return ""

    def extract_date_robust(self, item) -> str:
        """–†–æ–±—É—Å–Ω–æ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –Ω–∞ –¥–∞—Ç—É–º"""
        date_strategies = [
            lambda: item.find_element(By.CSS_SELECTOR, ".entry-date").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, ".post-date").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, ".date").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "[class*='date']").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "time").text.strip(),
            lambda: item.find_element(By.CSS_SELECTOR, "time").get_attribute('datetime'),
        ]

        for strategy in date_strategies:
            try:
                date = strategy()
                if date and len(date.strip()) > 0:
                    return date.strip()
            except (NoSuchElementException, Exception):
                continue
        return ""

    def scrape_event_details(self, event_url: str) -> Dict:
        """–í–ª–µ–≥—É–≤–∞ –≤–æ –ª–∏–Ω–∫–æ—Ç –Ω–∞ –Ω–∞—Å—Ç–∞–Ω–æ—Ç –∏ —Å–∫—Ä–µ–ø–∏—Ä–∞ –¥–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏"""
        details = {
            'description_full': '',
            'organizer': '',
            'category': '',
            'duration': '',
            'location_full': '',
            'image_url': '',
            'contact_info': '',
            'ticket_price_text': '',
            'ticket_free': True,
            'ticket_price_numeric': None
        }

        if not event_url or event_url == self.base_url:
            return details

        try:
            self.logger.info(f"  üìÑ –í–ª–µ–≥—É–≤–∞–º –≤–æ: {event_url}")
            self.driver.get(event_url)
            time.sleep(3)

            # 1. –û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä
            organizer_selectors = [".author", ".organizer", ".post-author", "[class*='author']", ".entry-meta"]
            for selector in organizer_selectors:
                try:
                    org_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if org_element and org_element.text.strip():
                        details['organizer'] = org_element.text.strip()
                        self.logger.info(f"    üè¢ –û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä: {details['organizer']}")
                        break
                except:
                    continue

            # 2. –û–ø–∏—Å
            description_selectors = [
                ".entry-content",
                ".post-content",
                ".content",
                "[class*='content']",
                "article .text",
                ".description"
            ]
            for selector in description_selectors:
                try:
                    desc_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if desc_element and desc_element.text.strip():
                        desc_text = desc_element.text.strip()
                        # –û—Ç—Å—Ç—Ä–∞–Ω–∏ –≤–∏—à–æ–∫ whitespace
                        desc_text = re.sub(r'\s+', ' ', desc_text)
                        if len(desc_text) > 50:  # –°–∞–º–æ –∞–∫–æ –∏–º–∞ –¥–æ–≤–æ–ª–Ω–æ —Å–æ–¥—Ä–∂–∏–Ω–∞
                            details['description_full'] = desc_text
                            self.logger.info(f"    üìù –û–ø–∏—Å: {desc_text[:100]}...")
                            break
                except:
                    continue

            # 3. –°–ª–∏–∫–∞
            image_selectors = [
                ".post-thumbnail img",
                ".featured-image img",
                "article img",
                ".entry-content img"
            ]
            for selector in image_selectors:
                try:
                    img_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    img_src = img_element.get_attribute('src')
                    if img_src and img_src.startswith('http'):
                        details['image_url'] = img_src
                        self.logger.info(f"    üñºÔ∏è –°–ª–∏–∫–∞: {img_src}")
                        break
                except:
                    continue

            # 4. –¶–µ–Ω–∞ –Ω–∞ –±–∏–ª–µ—Ç - –ù–û–í–û!
            price_info = self.extract_ticket_price_info()
            details.update(price_info)

        except Exception as e:
            self.logger.error(f"    ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ –¥–µ—Ç–∞–ª–∏: {e}")

        return details

    def extract_ticket_price_info(self) -> Dict:
        """–ò–∑–≤–ª–µ–∫—É–≤–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∑–∞ —Ü–µ–Ω–∞—Ç–∞ –Ω–∞ –±–∏–ª–µ—Ç–æ—Ç"""
        price_info = {
            'ticket_price_text': '',
            'ticket_free': True,
            'ticket_price_numeric': None
        }

        try:
            # –ó–µ–º–∏ –≥–æ —Ü–µ–ª–∏–æ—Ç —Ç–µ–∫—Å—Ç –æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞
            page_text = self.driver.find_element(By.TAG_NAME, "body").text.lower()

            # –ü—Ä–æ–≤–µ—Ä–∏ –∑–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–∏ –Ω–∞—Å—Ç–∞–Ω–∏
            free_keywords = [
                '–±–µ—Å–ø–ª–∞—Ç–Ω–æ', 'free', '–±–µ–∑ –Ω–∞–¥–æ–º–µ—Å—Ç', '–±–µ—Å–ø–ª–∞—Ç–µ–Ω –≤–ª–µ–∑',
                'no cost', '–±–µ–∑ –ø–ª–∞—ú–∞—ö–µ', '–±–µ—Å–ø–ª–∞—Ç–Ω–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—ò–∞'
            ]

            for keyword in free_keywords:
                if keyword in page_text:
                    price_info['ticket_price_text'] = '–ë–µ—Å–ø–ª–∞—Ç–Ω–æ'
                    price_info['ticket_free'] = True
                    self.logger.info(f"    üí∞ –¶–µ–Ω–∞: –ë–µ—Å–ø–ª–∞—Ç–Ω–æ (–Ω–∞—ò–¥–µ–Ω–æ: '{keyword}')")
                    return price_info

            # –°–µ–ª–µ–∫—Ç–æ—Ä–∏ –∑–∞ —Ü–µ–Ω–∏
            price_selectors = [
                ".price", ".ticket-price", ".cost", "[class*='price']",
                ".entry-price", ".event-price", "[class*='cost']",
                ".registration-fee", ".admission", "[class*='fee']"
            ]

            # –ü—Ä–æ–±–∞—ò –¥–∞ –Ω–∞—ò–¥–µ—à —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑–∞ —Ü–µ–Ω–∞
            for selector in price_selectors:
                try:
                    price_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in price_elements:
                        price_text = element.text.strip()
                        if price_text and self.contains_price_info(price_text):
                            extracted_price = self.parse_price_text(price_text)
                            if extracted_price:
                                price_info.update(extracted_price)
                                self.logger.info(f"    üí∞ –¶–µ–Ω–∞: {price_info['ticket_price_text']}")
                                return price_info
                except:
                    continue

            # –ü—Ä–µ–±–∞—Ä—É–≤–∞—ò —Å–æ regex –Ω–∏–∑ —Ü–µ–ª–∏–æ—Ç —Ç–µ–∫—Å—Ç
            price_patterns = [
                r'(?:—Ü–µ–Ω–∞|price|cost|–±–∏–ª–µ—Ç)[\s:]*(\d+(?:[,.]?\d+)?)\s*(?:–¥–µ–Ω|mkd|–µ–≤—Ä–∞?|eur|‚Ç¨|\$)',
                r'(\d+(?:[,.]?\d+)?)\s*(?:–¥–µ–Ω|mkd|–µ–≤—Ä–∞?|eur|‚Ç¨|\$)(?:\s*(?:–∑–∞ –±–∏–ª–µ—Ç|per ticket|—Ü–µ–Ω–∞))?',
                r'(?:—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—ò–∞|registration)[\s:]*(\d+(?:[,.]?\d+)?)\s*(?:–¥–µ–Ω|mkd|–µ–≤—Ä–∞?|eur|‚Ç¨|\$)',
                r'(?:–≤–ª–µ–∑|entrance|admission)[\s:]*(\d+(?:[,.]?\d+)?)\s*(?:–¥–µ–Ω|mkd|–µ–≤—Ä–∞?|eur|‚Ç¨|\$)'
            ]

            for pattern in price_patterns:
                matches = re.findall(pattern, page_text, re.IGNORECASE)
                if matches:
                    # –ó–µ–º–∏ —ò–∞ –ø—Ä–≤–∞—Ç–∞ —Ü–µ–Ω–∞ —à—Ç–æ —ò–∞ –Ω–∞—ò–¥–µ
                    price_num = matches[0].replace(',', '.')
                    try:
                        price_numeric = float(price_num)
                        # –û–ø—Ä–µ–¥–µ–ª–∏ –≤–∞–ª—É—Ç–∞ –≤—Ä–∑ –æ—Å–Ω–æ–≤–∞ –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                        currency = self.detect_currency_from_context(page_text, price_num)

                        price_info['ticket_price_text'] = f"{price_num} {currency}"
                        price_info['ticket_free'] = False
                        price_info['ticket_price_numeric'] = price_numeric

                        self.logger.info(f"    üí∞ –¶–µ–Ω–∞: {price_info['ticket_price_text']} (regex)")
                        return price_info
                    except ValueError:
                        continue

            # –ê–∫–æ –Ω–µ –µ –Ω–∞—ò–¥–µ–Ω–æ –Ω–∏—à—Ç–æ, –æ—Å—Ç–∞–Ω–∏ —Å–æ default (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)
            self.logger.info(f"    üí∞ –¶–µ–Ω–∞: –ù–µ –µ –ø—Ä–æ–Ω–∞—ò–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—ò–∞ (default: –±–µ—Å–ø–ª–∞—Ç–Ω–æ)")

        except Exception as e:
            self.logger.error(f"    ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ —Ü–µ–Ω–∞: {e}")

        return price_info

    def contains_price_info(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ —Ç–µ–∫—Å—Ç–æ—Ç —Å–æ–¥—Ä–∂–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∑–∞ —Ü–µ–Ω–∞"""
        price_indicators = [
            '–¥–µ–Ω', 'mkd', '–µ–≤—Ä–∞', 'eur', '‚Ç¨', '$', '—Ü–µ–Ω–∞', 'price',
            'cost', '–±–∏–ª–µ—Ç', 'ticket', '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—ò–∞', 'registration',
            '–≤–ª–µ–∑', 'entrance', 'admission', 'fee'
        ]

        text_lower = text.lower()
        has_number = re.search(r'\d+', text)
        has_price_word = any(word in text_lower for word in price_indicators)

        return has_number and has_price_word

    def parse_price_text(self, price_text: str) -> Dict:
        """–ü–∞—Ä—Å–∏—Ä–∞ —Ç–µ–∫—Å—Ç —Å–æ —Ü–µ–Ω–∞ –∏ –≤—Ä–∞—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏"""
        try:
            # –ò–∑–≤–ª–µ—á–∏ –±—Ä–æ—ò –æ–¥ —Ç–µ–∫—Å—Ç–æ—Ç
            number_match = re.search(r'(\d+(?:[,.]?\d+)?)', price_text)
            if not number_match:
                return None

            price_num = number_match.group(1).replace(',', '.')
            price_numeric = float(price_num)

            # –û–ø—Ä–µ–¥–µ–ª–∏ –≤–∞–ª—É—Ç–∞
            currency = self.detect_currency_from_context(price_text, price_num)

            return {
                'ticket_price_text': f"{price_num} {currency}",
                'ticket_free': False,
                'ticket_price_numeric': price_numeric
            }

        except (ValueError, AttributeError):
            return None

    def detect_currency_from_context(self, text: str, price_num: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏ –≤–∞–ª—É—Ç–∞ –≤—Ä–∑ –æ—Å–Ω–æ–≤–∞ –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        text_lower = text.lower()

        # –ü—Ä–æ–≤–µ—Ä–∏ –∑–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –≤–∞–ª—É—Ç–∏
        if any(curr in text_lower for curr in ['eur', '‚Ç¨', '–µ–≤—Ä–∞', '–µ–≤—Ä–æ']):
            return 'EUR'
        elif any(curr in text_lower for curr in ['$', 'usd', 'dollar']):
            return 'USD'
        elif any(curr in text_lower for curr in ['–¥–µ–Ω', 'mkd', '–¥–µ–Ω–∞—Ä']):
            return 'MKD'
        else:
            # Default –≤—Ä–∑ –æ—Å–Ω–æ–≤–∞ –Ω–∞ –≥–æ–ª–µ–º–∏–Ω–∞ –Ω–∞ —Ü–µ–Ω–∞—Ç–∞
            price_val = float(price_num.replace(',', '.'))
            if price_val > 100:  # –í–µ—Ä–æ—ò–∞—Ç–Ω–æ –¥–µ–Ω–∞—Ä–∏
                return 'MKD'
            else:  # –í–µ—Ä–æ—ò–∞—Ç–Ω–æ –µ–≤—Ä–∞
                return 'EUR'
    def find_event_containers(self) -> List:
        """–ù–∞—ò–¥–∏ –≥–∏ —Å–∏—Ç–µ –∫–æ–Ω—Ç–µ—ò–Ω–µ—Ä–∏ —à—Ç–æ —Å–æ–¥—Ä–∂–∞—Ç –Ω–∞—Å—Ç–∞–Ω–∏"""
        container_selectors = [
            "article.post.category-it-nastan",  # –û—Ä–∏–≥–∏–Ω–∞–ª–µ–Ω
            "article.post",
            "article[class*='nastan']",
            "article[class*='event']",
            ".post.category-it-nastan",
            ".post",
            "[class*='event-item']",
            "[class*='post-item']"
        ]

        for selector in container_selectors:
            try:
                containers = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if containers:
                    # –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ —Å–æ–¥—Ä–∂–∞—Ç IT –Ω–∞—Å—Ç–∞–Ω–∏ –ª–∏–Ω–∫–æ–≤–∏
                    valid_containers = []
                    for container in containers:
                        links = container.find_elements(By.TAG_NAME, "a")
                        for link in links:
                            href = link.get_attribute('href')
                            if href and 'it-nastan' in href:
                                valid_containers.append(container)
                                break

                    if valid_containers:
                        self.logger.info(
                            f"‚úÖ –ö–æ—Ä–∏—Å—Ç–∞–º —Å–µ–ª–µ–∫—Ç–æ—Ä '{selector}' - –Ω–∞—ò–¥–µ–Ω–∏ {len(valid_containers)} –∫–æ–Ω—Ç–µ—ò–Ω–µ—Ä–∏")
                        return valid_containers

            except Exception as e:
                self.logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä '{selector}' –Ω–µ —Ä–∞–±–æ—Ç–∏: {e}")
                continue

        # –ê–∫–æ –Ω–∏—à—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∏, –ø—Ä–æ–±–∞—ò –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ–Ω –ø—Ä–∏—Å—Ç–∞–ø
        self.logger.warning("‚ö†Ô∏è –ö–æ—Ä–∏—Å—Ç–∞–º –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ–Ω –ø—Ä–∏—Å—Ç–∞–ø - –±–∞—Ä–∞–º –¥–∏—Ä–µ–∫—Ç–Ω–æ –ª–∏–Ω–∫–æ–≤–∏")
        return self.find_events_by_links()

    def find_events_by_links(self) -> List:
        """–ê–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ–Ω –ø—Ä–∏—Å—Ç–∞–ø - –Ω–∞—ò–¥–∏ –≥–∏ –Ω–∞—Å—Ç–∞–Ω–∏—Ç–µ –ø–æ –ª–∏–Ω–∫–æ–≤–∏—Ç–µ"""
        try:
            # –ù–∞—ò–¥–∏ –≥–∏ —Å–∏—Ç–µ –ª–∏–Ω–∫–æ–≤–∏ —à—Ç–æ —Å–æ–¥—Ä–∂–∞—Ç "it-nastan"
            event_links = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="it-nastan"]')

            # –°–æ–∑–¥–∞—ò —Ñ–∏–∫—Ç–∏–≤–Ω–∏ –∫–æ–Ω—Ç–µ—ò–Ω–µ—Ä–∏ –æ–¥ —Ä–æ–¥–∏—Ç–µ–ª—Å–∫–∏—Ç–µ –µ–ª–µ–º–µ–Ω—Ç–∏
            containers = []
            seen_parents = set()

            for link in event_links:
                try:
                    # –û–¥–∏ –¥–æ —Ä–æ–¥–∏—Ç–µ–ª—Å–∫–∏–æ—Ç article –∏–ª–∏ div
                    parent = link
                    for _ in range(5):  # –ú–∞–∫—Å–∏–º—É–º 5 –Ω–∏–≤–æ–∞ –Ω–∞–≥–æ—Ä–µ
                        parent = parent.find_element(By.XPATH, "..")
                        tag = parent.tag_name.lower()
                        if tag in ['article', 'div'] and parent not in seen_parents:
                            containers.append(parent)
                            seen_parents.add(parent)
                            break
                except:
                    continue

            self.logger.info(f"üîó –ù–∞—ò–¥–µ–Ω–∏ {len(containers)} –∫–æ–Ω—Ç–µ—ò–Ω–µ—Ä–∏ –ø—Ä–µ–∫—É –ª–∏–Ω–∫–æ–≤–∏")
            return containers

        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ–Ω –ø—Ä–∏—Å—Ç–∞–ø: {e}")
            return []

    def extract_basic_event_data(self, event_items, source_name: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–∏ –æ—Å–Ω–æ–≤–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –ª–∏—Å—Ç–∞ –Ω–∞ event items"""
        events = []

        self.logger.info(f"üìä {source_name}: –û–±—Ä–∞–±–æ—Ç—É–≤–∞–º {len(event_items)} –µ–ª–µ–º–µ–Ω—Ç–∏...")

        for i, item in enumerate(event_items):
            try:
                if self.debug and i < 3:  # Debug –ø—Ä–≤–∏—Ç–µ 3
                    self.logger.info(f"\n--- –ï–ª–µ–º–µ–Ω—Ç {i + 1} ---")
                    self.logger.info(f"Tag: {item.tag_name}, Class: {item.get_attribute('class')}")

                event_data = {
                    'event_id': '',
                    'url': '',
                    'title': '',
                    'date_start': '',
                    'time_start': '',
                    'location': '',
                    'ticket_url': '',
                    'ticket_price_text': '',
                    'ticket_free': True,
                    'description': '',
                    'category': 'IT Event',
                    'organizer': '',
                    'duration': '',
                    'image_url': '',
                    'scraped_at': datetime.now().isoformat()
                }

                # –ò–∑–≤–ª–µ—á–∏ URL
                url = self.extract_url_robust(item)
                if url:
                    event_data['url'] = url
                    event_data['ticket_url'] = url

                # –ò–∑–≤–ª–µ—á–∏ –Ω–∞—Å–ª–æ–≤
                title = self.extract_title_robust(item)
                if title:
                    event_data['title'] = title

                # –ò–∑–≤–ª–µ—á–∏ –¥–∞—Ç—É–º
                date = self.extract_date_robust(item)
                if date:
                    event_data['date_start'] = date

                # –ì–µ–Ω–µ—Ä–∏—Ä–∞—ò event_id –∞–∫–æ –∏–º–∞–º–µ –Ω–∞—Å–ª–æ–≤
                if event_data['title']:
                    event_data['event_id'] = self.generate_event_id(
                        event_data['title'],
                        event_data['date_start']
                    )
                    event_data['description'] = f"IT –Ω–∞—Å—Ç–∞–Ω: {event_data['title']}"

                    events.append(event_data)
                    self.logger.info(f"   ‚úÖ {len(events)}. {event_data['title']}")

                    if self.debug:
                        self.logger.info(f"      URL: {event_data['url']}")
                        self.logger.info(f"      –î–∞—Ç—É–º: {event_data['date_start']}")
                else:
                    if self.debug:
                        self.logger.warning(f"   ‚ùå –ï–ª–µ–º–µ–Ω—Ç {i + 1}: –ù–µ–º–∞ –≤–∞–ª–∏–¥–µ–Ω –Ω–∞—Å–ª–æ–≤")

            except Exception as e:
                self.logger.error(f"   ‚ö†Ô∏è –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –µ–ª–µ–º–µ–Ω—Ç {i + 1}: {e}")
                continue

        self.logger.info(f"   ‚úÖ {source_name}: –°–æ–±—Ä–∞–Ω–∏ {len(events)} –≤–∞–ª–∏–¥–Ω–∏ –Ω–∞—Å—Ç–∞–Ω–∏")
        return events

    def scrape_events(self, max_pages: int = 50) -> List[Dict]:
        """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞ –∑–∞ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ –Ω–∞—Å—Ç–∞–Ω–∏"""
        self.logger.info("üöÄ –ó–∞–ø–æ—á–Ω—É–≤–∞–º —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ –Ω–∞—Å—Ç–∞–Ω–∏ –æ–¥ it.mk/tag/it-nastan/...")

        try:
            self.driver.get(self.it_nastan_url)
            self.logger.info(f"üìñ –í—á–∏—Ç–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {self.it_nastan_url}")
            time.sleep(5)

            # Debug —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–∫–æ –µ –ø–æ—Ç—Ä–µ–±–Ω–æ
            self.debug_page_structure()

            all_events = []
            page_num = 1

            while page_num <= max_pages:
                self.logger.info(f"\nüîç === –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{max_pages} ===")

                # –ù–∞—ò–¥–∏ –≥–∏ –∫–æ–Ω—Çej–Ω–µ—Ä–∏—Ç–µ –∑–∞ –Ω–∞—Å—Ç–∞–Ω–∏
                event_items = self.find_event_containers()

                if not event_items:
                    self.logger.warning(f"‚ùå –ù–µ–º–∞ –Ω–∞—Å—Ç–∞–Ω–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}")
                    break

                # –ò–∑–≤–ª–µ—á–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏
                page_events = self.extract_basic_event_data(event_items, f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}")
                all_events.extend(page_events)

                # –ü—Ä–æ–±–∞—ò –¥–∞ –æ–¥–∏—à –Ω–∞ —Å–ª–µ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                try:
                    next_selectors = [
                        "a.nextpostslink",
                        ".next-page",
                        ".pagination .next",
                        "a[rel='next']",
                        ".nav-next a"
                    ]

                    next_link = None
                    for selector in next_selectors:
                        try:
                            next_link = self.driver.find_element(By.CSS_SELECTOR, selector)
                            if next_link.is_displayed() and next_link.is_enabled():
                                break
                            next_link = None
                        except:
                            continue

                    if next_link:
                        next_href = next_link.get_attribute('href')
                        self.logger.info(f"   ‚û°Ô∏è –û–¥–∏ –Ω–∞ —Å–ª–µ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {next_href}")
                        self.driver.get(next_href)
                        time.sleep(5)
                        page_num += 1
                    else:
                        self.logger.info("   ‚ùå –ù–µ–º–∞ —Å–ª–µ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞")
                        break

                except Exception as e:
                    self.logger.error(f"   ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏—ò–∞: {e}")
                    break

            self.logger.info(f"\n‚úÖ –§–ê–ó–ê 1 –∑–∞–≤—Ä—à–µ–Ω–∞: –°–æ–±—Ä–∞–Ω–∏ {len(all_events)} –Ω–∞—Å—Ç–∞–Ω–∏ –æ–¥ {page_num} —Å—Ç—Ä–∞–Ω–∏—Ü–∏")

            # –û—Ç—Å—Ç—Ä–∞–Ω–∏ –¥—É–ø–ª–∏–∫–∞—Ç–∏
            unique_events = self.remove_duplicates(all_events)
            self.logger.info(f"üßπ –ü–æ—Å–ª–µ –æ—Ç—Å—Ç—Ä–∞–Ω—É–≤–∞—ö–µ –¥—É–ø–ª–∏–∫–∞—Ç–∏: {len(unique_events)} —É–Ω–∏–∫–∞—Ç–Ω–∏ –Ω–∞—Å—Ç–∞–Ω–∏")

            # –§–∞–∑–∞ 2: –î–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏
            detailed_events = self.scrape_detailed_data(unique_events)

            return detailed_events

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –≥—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ: {e}")
            return []

    def remove_duplicates(self, events: List[Dict]) -> List[Dict]:
        """–û—Ç—Å—Ç—Ä–∞–Ω–∏ –¥—É–ø–ª–∏–∫–∞—Ç–∏ –≤—Ä–∑ –±–∞–∑–∞ –Ω–∞ –Ω–∞—Å–ª–æ–≤ –∏ –¥–∞—Ç—É–º"""
        unique_events = []
        seen_events = set()

        for event in events:
            # –°–æ–∑–¥–∞—ò –∫–ª—É—á –∑–∞ —Å–ø–æ—Ä–µ–¥–±–∞
            key_parts = [
                event.get('title', '').lower().strip(),
                event.get('date_start', '').strip(),
                event.get('url', '').strip()
            ]
            event_key = '|'.join(key_parts)

            if event_key not in seen_events and event.get('title'):
                unique_events.append(event)
                seen_events.add(event_key)
            else:
                self.logger.debug(f"üóëÔ∏è –î—É–ø–ª–∏–∫–∞—Ç –æ—Ç—Å—Ç—Ä–∞–Ω–µ—Ç: {event.get('title', 'No title')}")

        return unique_events

    def scrape_detailed_data(self, events: List[Dict]) -> List[Dict]:
        """–§–∞–∑–∞ 2: –°–æ–±–∏—Ä–∞—ò –¥–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ —Å–µ–∫–æ—ò –Ω–∞—Å—Ç–∞–Ω"""
        if not events:
            return []

        self.logger.info(f"\nüé¨ === –§–ê–ó–ê 2: –î–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ {len(events)} –Ω–∞—Å—Ç–∞–Ω–∏ ===")

        detailed_events = []
        for i, event in enumerate(events):
            self.logger.info(f"\nüé≠ {i + 1}/{len(events)} - {event['title']}")

            if event.get('url') and event['url'] != self.base_url:
                try:
                    details = self.scrape_event_details(event['url'])

                    # –ú–µ—Ä—ü–∏—Ä–∞—ò –≥–∏ –¥–µ—Ç–∞–ª–∏—Ç–µ
                    if details['description_full']:
                        event['description'] = details['description_full']
                    if details['organizer']:
                        event['organizer'] = details['organizer']
                    if details['image_url']:
                        event['image_url'] = details['image_url']

                    # –î–æ–¥–∞—ò –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ –¥–µ—Ç–∞–ª–∏—Ç–µ
                    event.update({k: v for k, v in details.items() if v})

                except Exception as e:
                    self.logger.error(f"    ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –¥–µ—Ç–∞–ª–Ω–æ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ: {e}")
            else:
                self.logger.info("    ‚è≠Ô∏è –ü—Ä–µ—Å–∫–æ–∫–Ω—É–≤–∞–º (–Ω–µ–º–∞ –≤–∞–ª–∏–¥–µ–Ω –ª–∏–Ω–∫)")

            detailed_events.append(event)

        self.logger.info(f"\n‚úÖ –§–ê–ó–ê 2 –∑–∞–≤—Ä—à–µ–Ω–∞: {len(detailed_events)} –Ω–∞—Å—Ç–∞–Ω–∏ —Å–æ –¥–µ—Ç–∞–ª–∏")
        return detailed_events

    def save_to_csv(self, events: List[Dict], filename_suffix: str = "") -> str:
        """–ó–∞—á—É–≤–∞—ò –≥–∏ –Ω–∞—Å—Ç–∞–Ω–∏—Ç–µ –≤–æ CSV"""
        if not events:
            self.logger.warning("–ù–µ–º–∞ –Ω–∞—Å—Ç–∞–Ω–∏ –∑–∞ –∑–∞—á—É–≤—É–≤–∞—ö–µ")
            return ""

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if filename_suffix:
            filename = f"it_events_{filename_suffix}_{timestamp}.csv"
        else:
            filename = f"it_events_{timestamp}.csv"

        filepath = os.path.join(self.processed_data_dir, filename)

        try:
            df = pd.DataFrame(events)
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            self.logger.info(f"üíæ –ó–∞—á—É–≤–∞–Ω–∏ {len(events)} –Ω–∞—Å—Ç–∞–Ω–∏ –≤–æ: {filepath}")
            return filepath
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—á—É–≤—É–≤–∞—ö–µ: {e}")
            return ""

    def print_summary(self, events: List[Dict]):
        """–ü—Ä–∏–∫–∞–∂–∏ —Ä–µ–∑–∏–º–µ –æ–¥ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ—Ç–æ"""
        if not events:
            self.logger.info("üìä –ù–µ–º–∞ –Ω–∞—Å—Ç–∞–Ω–∏ –∑–∞ –ø—Ä–∏–∫–∞–∑")
            return

        self.logger.info(f"\nüìä === –†–ï–ó–ò–ú–ï ===")
        self.logger.info(f"–í–∫—É–ø–Ω–æ –Ω–∞—Å—Ç–∞–Ω–∏: {len(events)}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        with_description = sum(1 for e in events if e.get('description') and len(e['description']) > 50)
        with_organizer = sum(1 for e in events if e.get('organizer'))
        with_date = sum(1 for e in events if e.get('date_start'))
        with_image = sum(1 for e in events if e.get('image_url'))

        self.logger.info(f"–°–æ –æ–ø–∏—Å: {with_description}")
        self.logger.info(f"–°–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä: {with_organizer}")
        self.logger.info(f"–°–æ –¥–∞—Ç—É–º: {with_date}")
        self.logger.info(f"–°–æ —Å–ª–∏–∫–∞: {with_image}")

        # –ü—Ä–∏–º–µ—Ä–∏
        self.logger.info(f"\nüìã –ü—Ä–≤–∏—Ç–µ 3 –Ω–∞—Å—Ç–∞–Ω–∏:")
        for i, event in enumerate(events[:3]):
            self.logger.info(f"{i + 1}. {event.get('title', '–ë–µ–∑ –Ω–∞—Å–ª–æ–≤')}")
            self.logger.info(f"   –î–∞—Ç—É–º: {event.get('date_start', '–ë–µ–∑ –¥–∞—Ç—É–º')}")
            self.logger.info(f"   URL: {event.get('url', '–ë–µ–∑ URL')}")

    def run_full_scrape(self, max_pages: int = 50, save_results: bool = True) -> List[Dict]:
        """–ò–∑–≤—Ä—à–∏ —Ü–µ–ª–æ—Å–Ω–æ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ"""
        try:
            self.logger.info("üöÄ === –ó–ê–ü–û–ß–ù–£–í–ê–ú –°–ö–†–ï–ü–ò–†–ê–ä–ï ===")

            # Setup
            self.setup_driver()

            # –°–∫—Ä–µ–ø–∏—Ä–∞—ò
            events = self.scrape_events(max_pages)

            # –ó–∞—á—É–≤–∞—ò –∞–∫–æ –µ –ø–æ—Ç—Ä–µ–±–Ω–æ
            if save_results and events:
                self.save_to_csv(events, "final")

            # –ü—Ä–∏–∫–∞–∂–∏ —Ä–µ–∑–∏–º–µ
            self.print_summary(events)

            self.logger.info("‚úÖ === –°–ö–†–ï–ü–ò–†–ê–ä–ï–¢–û –ó–ê–í–†–®–ï–ù–û ===")
            return events

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –≥—Ä–µ—à–∫–∞: {e}")
            return []
        finally:
            self.close_driver()


def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞"""
    print("üéØ IT Events Scraper - –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –≤–µ—Ä–∑–∏—ò–∞")
    print("=" * 50)

    # –ö—Ä–µ–∏—Ä–∞—ò —Å–∫—Ä–µ–ø–µ—Ä —Å–æ debug
    scraper = ITEventsScraper(debug=True)

    try:
        # –ò–∑–±—Ä–∏—à–∏ —Å—Ç–∞—Ä–∏ —Ñ–∞—ò–ª–æ–≤–∏
        scraper.clean_old_files()

        # –°–∫—Ä–µ–ø–∏—Ä–∞—ò –Ω–∞—Å—Ç–∞–Ω–∏
        events = scraper.run_full_scrape(max_pages=50, save_results=True)

        if events:
            print(f"\nüéâ –£—Å–ø–µ—à–Ω–æ —Å–∫—Ä–µ–ø–∏—Ä–∞–Ω–∏ {len(events)} –Ω–∞—Å—Ç–∞–Ω–∏!")

            # –ü—Ä–∏–∫–∞–∂–∏ –Ω–µ–∫–æ–ª–∫—É –ø—Ä–∏–º–µ—Ä–∏
            print("\nüìã –ü—Ä–∏–º–µ—Ä–∏:")
            for i, event in enumerate(events[:3]):
                print(f"{i + 1}. {event.get('title', '–ë–µ–∑ –Ω–∞—Å–ª–æ–≤')}")
                print(f"   üìÖ –î–∞—Ç—É–º: {event.get('date_start', '–ë–µ–∑ –¥–∞—Ç—É–º')}")
                print(f"   üè¢ –û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä: {event.get('organizer', '–ù–µ–ø–æ–∑–Ω–∞—Ç')}")
                print(f"   üîó URL: {event.get('url', '–ë–µ–∑ URL')}")
                print(f"   üìù –û–ø–∏—Å: {event.get('description', '–ë–µ–∑ –æ–ø–∏—Å')[:100]}...")
                print()
        else:
            print("‚ùå –ù–µ —Å–µ —Å–∫—Ä–µ–ø–∏—Ä–∞–Ω–∏ –Ω–∞—Å—Ç–∞–Ω–∏. –ü—Ä–æ–≤–µ—Ä–µ—Ç–µ —ò–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–∞—Ç–∞.")

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –°–∫—Ä–µ–ø–∏—Ä–∞—ö–µ—Ç–æ –µ –ø—Ä–µ–∫–∏–Ω–∞—Ç–æ –æ–¥ –∫–æ—Ä–∏—Å–Ω–∏–∫–æ—Ç")
    except Exception as e:
        print(f"\n‚ùå –ù–µ–æ—á–µ–∫—É–≤–∞–Ω–∞ –≥—Ä–µ—à–∫–∞: {e}")
    finally:
        print("\nüëã –ö—Ä–∞—ò –Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–∞—Ç–∞")


if __name__ == "__main__":
    main()