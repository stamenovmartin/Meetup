#!/usr/bin/env python3

import time
import re
from datetime import datetime
from typing import List, Dict, Optional
import pandas as pd
import selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import os
import glob
import hashlib
import logging

# –ó–∞ –ø–∞—Ä—Å–∏—Ä–∞—ö–µ –Ω–∞ HTML
try:
    from bs4 import BeautifulSoup

    HAS_BS4 = True
except ImportError:
    HAS_BS4 = False
    selenium.webdriver.common.by
    import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import os
import glob
import hashlib
import logging


class KartiEventsScraper:
    """
    –°–∫—Ä–µ–ø–µ—Ä –∑–∞ –Ω–∞—Å—Ç–∞–Ω–∏ –æ–¥ karti.com.mk
    —Å–æ –¥–µ—Ç–∞–ª–Ω–æ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–¥ —Å–µ–∫–æ—ò –Ω–∞—Å—Ç–∞–Ω
    """

    def __init__(self, debug=True):
        self.base_url = "https://karti.com.mk"
        self.events_url = "https://karti.com.mk"
        self.driver = None
        self.wait = None
        self.debug = debug
        self.raw_data_dir = "../raw_data"
        self.processed_data_dir = "../processed_data"

        # Setup logging
        logging.basicConfig(
            level=logging.INFO if debug else logging.WARNING,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)

        os.makedirs(self.raw_data_dir, exist_ok=True)
        os.makedirs(self.processed_data_dir, exist_ok=True)

    def clean_old_files(self):
        """–û—Ç—Å—Ç—Ä–∞–Ω–∏ —Å—Ç–∞—Ä–∏ —Ñ–∞—ò–ª–æ–≤–∏"""
        old_raw_files = glob.glob(os.path.join(self.raw_data_dir, "karti_events_raw_*.csv"))
        old_processed_files = glob.glob(os.path.join(self.processed_data_dir, "karti_events_*.csv"))

        for file_path in old_raw_files + old_processed_files:
            os.remove(file_path)
            self.logger.info(f"–û—Ç—Å—Ç—Ä–∞–Ω–µ—Ç —Ñ–∞—ò–ª: {file_path}")

    def setup_driver(self):
        """Setup Chrome driver —Å–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∏ –æ–ø—Ü–∏–∏"""
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-plugins")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument(
            "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )

        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.set_page_load_timeout(30)
            self.wait = WebDriverWait(self.driver, 10)
            self.logger.info("‚úÖ Chrome driver —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç–∞–≤–µ–Ω")
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç–∞–≤—É–≤–∞—ö–µ –Ω–∞ driver: {e}")
            raise

    def close_driver(self):
        """–ó–∞—Ç–≤–æ—Ä–∏ –≥–æ driver-ot"""
        if self.driver:
            self.driver.quit()
            self.logger.info("üîí Driver –∑–∞—Ç–≤–æ—Ä–µ–Ω")

    def generate_event_id(self, title: str, date: str = "") -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–∞ —É–Ω–∏–∫–∞—Ç–µ–Ω event_id"""
        clean_title = re.sub(r'[^\w\s]', '', title.lower())
        combined = f"{clean_title}_{date}".strip('_')
        return hashlib.md5(combined.encode()).hexdigest()

    def parse_date(self, date_text: str) -> str:
        """–ü–∞—Ä—Å–∏—Ä–∞—ò –¥–∞—Ç—É–º –æ–¥ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ñ–æ—Ä–º–∞—Ç–∏"""
        if not date_text:
            return ""

        # –ü–æ—á–∏—Å—Ç–∏ –≥–æ —Ç–µ–∫—Å—Ç–æ—Ç
        date_text = date_text.strip()

        # –ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏ –º–µ—Å–µ—Ü–∏ mapping
        mk_months = {
            '–à–∞–Ω—É–∞—Ä–∏': '01', '–§–µ–≤—Ä—É–∞—Ä–∏': '02', '–ú–∞—Ä—Ç': '03', '–ê–ø—Ä–∏–ª': '04',
            '–ú–∞—ò': '05', '–à—É–Ω–∏': '06', '–à—É–ª–∏': '07', '–ê–≤–≥—É—Å—Ç': '08',
            '–°–µ–ø—Ç–µ–º–≤—Ä–∏': '09', '–û–∫—Ç–æ–º–≤—Ä–∏': '10', '–ù–æ–µ–º–≤—Ä–∏': '11', '–î–µ–∫–µ–º–≤—Ä–∏': '12',
            '—ò–∞–Ω—É–∞—Ä–∏': '01', '—Ñ–µ–≤—Ä—É–∞—Ä–∏': '02', '–º–∞—Ä—Ç': '03', '–∞–ø—Ä–∏–ª': '04',
            '–º–∞—ò': '05', '—ò—É–Ω–∏': '06', '—ò—É–ª–∏': '07', '–∞–≤–≥—É—Å—Ç': '08',
            '—Å–µ–ø—Ç–µ–º–≤—Ä–∏': '09', '–æ–∫—Ç–æ–º–≤—Ä–∏': '10', '–Ω–æ–µ–º–≤—Ä–∏': '11', '–¥–µ–∫–µ–º–≤—Ä–∏': '12'
        }

        # –ê–∫–æ –µ –≤–æ —Ñ–æ—Ä–º–∞—Ç "22 –ê–≤–≥—É—Å—Ç 2025"
        for mk_month, num_month in mk_months.items():
            if mk_month in date_text:
                parts = date_text.replace(mk_month, num_month).split()
                if len(parts) >= 3:
                    day = parts[0].zfill(2)
                    month = num_month
                    year = parts[2]
                    return f"{year}-{month}-{day}"

        return date_text

    def parse_price(self, price_text: str) -> Dict:
        """–ü–∞—Ä—Å–∏—Ä–∞—ò —Ü–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        result = {
            'price_text': price_text,
            'price_min': None,
            'price_max': None,
            'currency': 'MKD',
            'is_free': False
        }

        if not price_text:
            return result

        price_text = price_text.strip()

        # –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ –µ –±–µ—Å–ø–ª–∞—Ç–Ω–æ
        if any(word in price_text.lower() for word in ['–±–µ—Å–ø–ª–∞—Ç–Ω–æ', 'free', '–±–µ—Å–ø–ª–∞—Ç–µ–Ω']):
            result['is_free'] = True
            return result

        # –ü—Ä–æ–Ω–∞—ò–¥–∏ –±—Ä–æ–µ–≤–∏ –≤–æ —Ç–µ–∫—Å—Ç–æ—Ç
        numbers = re.findall(r'\d+', price_text)
        if numbers:
            if len(numbers) == 1:
                result['price_min'] = int(numbers[0])
                result['price_max'] = int(numbers[0])
            elif len(numbers) >= 2:
                result['price_min'] = int(numbers[0])
                result['price_max'] = int(numbers[-1])

        # –î–µ—Ç–µ–∫—Ç–∏—Ä–∞—ò –≤–∞–ª—É—Ç–∞
        if 'EUR' in price_text.upper() or '‚Ç¨' in price_text:
            result['currency'] = 'EUR'
        elif 'USD' in price_text.upper() or '$' in price_text:
            result['currency'] = 'USD'

        return result

    def extract_event_from_card(self, event_card) -> Dict:
        """–ò–∑–≤–ª–µ—á–∏ –æ—Å–Ω–æ–≤–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ event card"""
        event_data = {
            'event_id': '',
            'url': '',
            'title': '',
            'date_start': '',
            'date_end': '',
            'time_start': '',
            'location': '',
            'venue': '',
            'ticket_url': '',
            'ticket_price_text': '',
            'price_min': None,
            'price_max': None,
            'currency': 'MKD',
            'ticket_free': False,
            'description': '',
            'category': '',
            'organizer': '',
            'image_url': '',
            'scraped_at': datetime.now().isoformat()
        }

        try:
            # 1. URL - event_card —Å–∞–º–∏–æ—Ç –µ –ª–∏–Ω–∫
            href = event_card.get_attribute('href')
            if href:
                if not href.startswith('http'):
                    href = self.base_url + '/' + href.lstrip('/')
                event_data['url'] = href
                event_data['ticket_url'] = href

            # 2. –ù–∞—Å–ª–æ–≤
            title_element = event_card.find_element(By.CSS_SELECTOR, ".k-event-list-event-title")
            if title_element:
                event_data['title'] = title_element.text.strip()

            # 3. –î–∞—Ç—É–º
            date_element = event_card.find_element(By.CSS_SELECTOR, ".k-events-event-date")
            if date_element:
                date_text = date_element.text.strip()
                event_data['date_start'] = self.parse_date(date_text)

                # –ê–∫–æ –∏–º–∞ range (–Ω–ø—Ä "22-23 –ê–≤–≥—É—Å—Ç 2025")
                if '-' in date_text and not date_text.startswith('http'):
                    parts = date_text.split('-')
                    if len(parts) >= 2:
                        # –°–µ –æ–±–∏–¥—É–≤–∞–º–µ –¥–∞ –Ω–∞–ø—Ä–∞–≤–∏–º–µ end date
                        end_part = parts[1].strip()
                        event_data['date_end'] = self.parse_date(end_part)

            # 4. –õ–æ–∫–∞—Ü–∏—ò–∞/Venue
            venue_element = event_card.find_element(By.CSS_SELECTOR, ".k-events-venue-details")
            if venue_element:
                venue_text = venue_element.text.strip()
                event_data['venue'] = venue_text
                event_data['location'] = venue_text

            # 5. –¶–µ–Ω–∞
            try:
                price_element = event_card.find_element(By.CSS_SELECTOR, ".cost")
                if price_element:
                    price_text = price_element.text.strip()
                    event_data['ticket_price_text'] = price_text

                    # –ü–∞—Ä—Å–∏—Ä–∞—ò —ò–∞ —Ü–µ–Ω–∞—Ç–∞
                    price_info = self.parse_price(price_text)
                    event_data.update(price_info)
                    event_data['ticket_free'] = price_info['is_free']
            except NoSuchElementException:
                pass

            # 6. –°–ª–∏–∫–∞
            try:
                img_element = event_card.find_element(By.CSS_SELECTOR, ".k-events-event-image img")
                if img_element:
                    img_src = img_element.get_attribute('src')
                    if img_src:
                        if not img_src.startswith('http'):
                            img_src = self.base_url + '/' + img_src.lstrip('/')
                        event_data['image_url'] = img_src
            except NoSuchElementException:
                pass

            # 7. –ö–∞—Ç–µ–≥–æ—Ä–∏—ò–∞ –æ–¥ CSS –∫–ª–∞—Å–∏—Ç–µ –Ω–∞ —Å–∞–º–∏–æ—Ç card
            class_attr = event_card.get_attribute('class')
            if class_attr:
                if 'concerts' in class_attr:
                    event_data['category'] = '–ö–æ–Ω—Ü–µ—Ä—Ç'
                elif 'festivals' in class_attr:
                    event_data['category'] = '–§–µ—Å—Ç–∏–≤–∞–ª'
                elif 'theater' in class_attr:
                    event_data['category'] = '–¢–µ–∞—Ç–∞—Ä'
                elif 'sport_events' in class_attr:
                    event_data['category'] = '–°–ø–æ—Ä—Ç'
                elif 'philharmonic' in class_attr:
                    event_data['category'] = '–§–∏–ª—Ö–∞—Ä–º–æ–Ω–∏—ò–∞'
                elif 'mob' in class_attr:
                    event_data['category'] = '–û–ø–µ—Ä–∞/–ë–∞–ª–µ—Ç'
                else:
                    event_data['category'] = '–ù–∞—Å—Ç–∞–Ω'

            # 8. –ì–µ–Ω–µ—Ä–∏—Ä–∞—ò event_id
            if event_data['title']:
                event_data['event_id'] = self.generate_event_id(
                    event_data['title'],
                    event_data['date_start']
                )

                # –û—Å–Ω–æ–≤–µ–Ω –æ–ø–∏—Å
                event_data['description'] = f"{event_data['category']}: {event_data['title']}"

            return event_data

        except Exception as e:
            self.logger.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ–∫—É–≤–∞—ö–µ –æ–¥ card: {e}")
            return event_data

    def parse_description_details(self, description: str) -> Dict:
        """–ü–∞—Ä—Å–∏—Ä–∞—ò –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ –¥–µ—Ç–∞–ª–∏ –æ–¥ –æ–ø–∏—Å–æ—Ç"""
        details = {
            'parsed_price': '',
            'parsed_time': '',
            'parsed_venue': '',
            'parsed_date': '',
            'additional_prices': [],
            'contact_info': '',
            'event_type': ''
        }

        if not description:
            return details

        # 1. –ò–∑–≤–ª–µ—á–∏ —Ü–µ–Ω–∏ –æ–¥ –æ–ø–∏—Å–æ—Ç
        # –ü—Ä–∏–º–µ—Ä: "2990-3990 –º–∫–¥", "70 eur / 4300 –º–∫–¥", "300 –º–∫–¥"
        price_patterns = [
            r'(\d+[-‚Äì]\d+)\s*(–º–∫–¥|eur|usd|–¥–µ–Ω–∞—Ä–∏)',
            r'(\d+)\s*(eur|usd)\s*/\s*(\d+)\s*(–º–∫–¥|–¥–µ–Ω–∞—Ä–∏)',
            r'(\d+)\s*(–º–∫–¥|eur|usd|–¥–µ–Ω–∞—Ä–∏)',
            r'(\d+[-‚Äì]\d+)\s*(eur|usd)',
            r'–±–∏–ª–µ—Ç–∏:\s*(\d+[-‚Äì]\d+)\s*(–º–∫–¥|eur)',
            r'—Ü–µ–Ω–∞:\s*(\d+[-‚Äì]\d+)\s*(–º–∫–¥|eur)',
            r'–∫–∞—Ä—Ç–∏:\s*(\d+[-‚Äì]\d+)\s*(–º–∫–¥|eur)'
        ]

        prices_found = []
        for pattern in price_patterns:
            matches = re.findall(pattern, description, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    price_text = ' '.join(match).strip()
                else:
                    price_text = match.strip()
                if price_text not in prices_found:
                    prices_found.append(price_text)

        if prices_found:
            details['parsed_price'] = ' | '.join(prices_found)
            details['additional_prices'] = prices_found

        # 2. –ò–∑–≤–ª–µ—á–∏ –≤—Ä–µ–º–µ
        # –ü—Ä–∏–º–µ—Ä: "20:00", "22:00", "09:00"
        time_patterns = [
            r'(\d{1,2}:\d{2})',
            r'–≤–æ\s*(\d{1,2}:\d{2})',
            r'–ø–æ—á–µ—Ç–æ–∫\s*(\d{1,2}:\d{2})',
            r'—Å—Ç–∞—Ä—Ç\s*(\d{1,2}:\d{2})'
        ]

        for pattern in time_patterns:
            match = re.search(pattern, description, re.IGNORECASE)
            if match:
                details['parsed_time'] = match.group(1)
                break

        # 3. –ò–∑–≤–ª–µ—á–∏ venue/–ª–æ–∫–∞—Ü–∏—ò–∞ –æ–¥ –æ–ø–∏—Å–æ—Ç
        # –û–±–∏—á–Ω–æ –µ –ø–æ –≤—Ä–µ–º–µ, –ø—Ä–µ–¥ –æ–ø–∏—Å
        venue_patterns = [
            r'(\d{1,2}:\d{2})\s+([^–ê-–®]+?)(?=[–ê-–®]|$)',  # –ü–æ—Å–ª–µ –≤—Ä–µ–º–µ –¥–æ –ø—Ä–≤ –º–∞–∫–µ–¥–æ–Ω—Å–∫–∏ –∑–±–æ—Ä
            r'–º–∫–¥\s+\d{1,2}:\d{2}\s+([^–ê-–®\n]+)',  # –ü–æ—Å–ª–µ —Ü–µ–Ω–∞ –∏ –≤—Ä–µ–º–µ
            r'eur\s+\d{1,2}:\d{2}\s+([^–ê-–®\n]+)'  # –ü–æ—Å–ª–µ EUR —Ü–µ–Ω–∞ –∏ –≤—Ä–µ–º–µ
        ]

        for pattern in venue_patterns:
            match = re.search(pattern, description, re.IGNORECASE)
            if match:
                venue = match.group(-1).strip()
                if len(venue) > 5 and len(venue) < 100:  # –†–∞–∑—É–º–Ω–∞ –¥–æ–ª–∂–∏–Ω–∞
                    details['parsed_venue'] = venue
                    break

        # 4. –ö–æ–Ω—Ç–∞–∫—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        contact_patterns = [
            r'—Ç–µ–ª\.?\s*:?\s*(\d{2,3}[-\s]*\d{3}[-\s]*\d{3,4})',
            r'—Ç–µ–ª–µ—Ñ–æ–Ω\s*:?\s*(\d{2,3}[-\s]*\d{3}[-\s]*\d{3,4})',
            r'–∫–æ–Ω—Ç–∞–∫—Ç\s*:?\s*(\d{2,3}[-\s]*\d{3}[-\s]*\d{3,4})',
            r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',  # email
            r'(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',  # website
            r'(facebook\.com/[a-zA-Z0-9._-]+)',
            r'(instagram\.com/[a-zA-Z0-9._-]+)'
        ]

        contacts = []
        for pattern in contact_patterns:
            matches = re.findall(pattern, description, re.IGNORECASE)
            contacts.extend(matches)

        if contacts:
            details['contact_info'] = ' | '.join(contacts)

        # 5. –¢–∏–ø –Ω–∞ –Ω–∞—Å—Ç–∞–Ω –æ–¥ –∫–ª—É—á–Ω–∏ –∑–±–æ—Ä–æ–≤–∏
        event_types = {
            '–∫–æ–Ω—Ü–µ—Ä—Ç': ['–∫–æ–Ω—Ü–µ—Ä—Ç', '–Ω–∞—Å—Ç–∞–ø', '–º—É–∑–∏–∫–∞', '–ø–µ—ò–∞—á', '–±–µ–Ω–¥'],
            '—Ñ–µ—Å—Ç–∏–≤–∞–ª': ['—Ñ–µ—Å—Ç–∏–≤–∞–ª', 'festival'],
            '—Ç–µ–∞—Ç–∞—Ä': ['—Ç–µ–∞—Ç–∞—Ä', '–ø—Ä–µ—Ç—Å—Ç–∞–≤–∞', 'drama', 'comedy'],
            '—Å–ø–æ—Ä—Ç': ['–Ω–∞—Ç–ø—Ä–µ–≤–∞—Ä', '—Ñ—É–¥–±–∞–ª', '–∫–æ—à–∞—Ä–∫–∞', '—Å–ø–æ—Ä—Ç'],
            '–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—ò–∞': ['—Ñ–æ—Ä—É–º', '–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—ò–∞', '—Å–µ–º–∏–Ω–∞—Ä', 'work'],
            '–∑–∞–±–∞–≤–∞': ['–ø–∞—Ä—Ç–∏', '–∂—É—Ä–∫–∞', 'party', 'dance']
        }

        for event_type, keywords in event_types.items():
            for keyword in keywords:
                if keyword.lower() in description.lower():
                    details['event_type'] = event_type
                    break
            if details['event_type']:
                break

        return details

    def scrape_event_details(self, event_url: str) -> Dict:
        """–í–ª–µ–≥—É–≤–∞ –≤–æ –ª–∏–Ω–∫–æ—Ç –Ω–∞ –Ω–∞—Å—Ç–∞–Ω–æ—Ç –∏ —Å–∫—Ä–µ–ø–∏—Ä–∞ –¥–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏"""
        details = {
            'description_full': '',
            'organizer': '',
            'contact_info': '',
            'additional_info': '',
            'event_details': '',
            'age_restriction': '',
            'dress_code': '',
            'ticket_info': '',
            'parsed_details': {}
        }

        if not event_url:
            return details

        try:
            self.logger.info(f"  üìÑ –í–ª–µ–≥—É–≤–∞–º –≤–æ: {event_url}")
            self.driver.get(event_url)
            time.sleep(3)

            # 1. –û—Å–Ω–æ–≤–µ–Ω –æ–ø–∏—Å/—Å–æ–¥—Ä–∂–∏–Ω–∞ - –∑–µ–º–∏ –ì–ò –°–ò–¢–ï –º–æ–∂–Ω–∏ –∏–∑–≤–æ—Ä–∏
            description_selectors = [
                "body",  # –¶–µ–ª–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∞–∫–æ –µ –ø–æ—Ç—Ä–µ–±–Ω–æ
                "main",
                ".container",
                ".content",
                ".event-description",
                ".event-content",
                ".description",
                ".event-details",
                "[class*='description']",
                "[class*='content']",
                ".entry-content",
                "article",
                ".text"
            ]

            best_description = ""
            for selector in description_selectors:
                try:
                    desc_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if desc_element:
                        desc_text = desc_element.text.strip()
                        # –û—Ç—Å—Ç—Ä–∞–Ω–∏ –≤–∏—à–æ–∫ whitespace
                        desc_text = re.sub(r'\s+', ' ', desc_text)

                        # –ó–µ–º–∏ –≥–æ –Ω–∞—ò–¥–æ–ª–≥–∏–æ—Ç –æ–ø–∏—Å
                        if len(desc_text) > len(best_description):
                            best_description = desc_text

                except NoSuchElementException:
                    continue

            if best_description and len(best_description) > 20:
                details['description_full'] = best_description
                self.logger.info(f"    üìù –û–ø–∏—Å: {best_description[:100]}...")

                # –ü–∞—Ä—Å–∏—Ä–∞—ò –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ –¥–µ—Ç–∞–ª–∏ –æ–¥ –æ–ø–∏—Å–æ—Ç
                parsed = self.parse_description_details(best_description)
                details['parsed_details'] = parsed

                if parsed['parsed_price']:
                    self.logger.info(f"    üí∞ –ü–∞—Ä—Å–∏—Ä–∞–Ω–∏ —Ü–µ–Ω–∏: {parsed['parsed_price']}")
                if parsed['parsed_time']:
                    self.logger.info(f"    üïê –ü–∞—Ä—Å–∏—Ä–∞–Ω–æ –≤—Ä–µ–º–µ: {parsed['parsed_time']}")
                if parsed['parsed_venue']:
                    self.logger.info(f"    üìç –ü–∞—Ä—Å–∏—Ä–∞–Ω venue: {parsed['parsed_venue']}")
                if parsed['contact_info']:
                    self.logger.info(f"    üìû –ö–æ–Ω—Ç–∞–∫—Ç: {parsed['contact_info']}")

            # 2. –ü—Ä–æ–±–∞—ò –¥–∞ –Ω–∞—ò–¥–µ—à —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–∏/–ø—Ä–æ–¥–∞–≤–∞—á–∏
            organizer_selectors = [
                ".organizer",
                ".event-organizer",
                ".promoter",
                ".seller",
                ".vendor",
                "[class*='organizer']",
                "[class*='promoter']",
                ".event-info .organizer",
                ".meta .organizer",
                ".author"
            ]

            for selector in organizer_selectors:
                try:
                    org_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if org_element and org_element.text.strip():
                        org_text = org_element.text.strip()
                        if len(org_text) < 100:  # –ù–µ –ø—Ä–µ–≥–æ–ª–µ–º —Ç–µ–∫—Å—Ç
                            details['organizer'] = org_text
                            self.logger.info(f"    üè¢ –û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä: {details['organizer']}")
                            break
                except NoSuchElementException:
                    continue

            # 3. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ –¥–µ—Ç–∞–ª–∏ - –∑–µ–º–∏ —Å√® —à—Ç–æ –µ –¥–æ—Å—Ç–∞–ø–Ω–æ
            try:
                # –ü—Ä–æ–±–∞—ò –¥–∞ –∑–µ–º–µ—à —Å√® –æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞
                page_source = self.driver.page_source
                if page_source and len(page_source) > 1000:
                    # –û—Ç—Å—Ç—Ä–∞–Ω–∏ HTML —Ç–∞–≥–æ–≤–∏ –∏ –∏–∑–≤–ª–µ—á–∏ —á–∏—Å—Ç —Ç–µ–∫—Å—Ç
                    if HAS_BS4:
                        try:
                            soup = BeautifulSoup(page_source, 'html.parser')
                            clean_text = soup.get_text()
                            # –ü–æ—á–∏—Å—Ç–∏ –≥–æ —Ç–µ–∫—Å—Ç–æ—Ç
                            clean_text = re.sub(r'\s+', ' ', clean_text).strip()

                            if len(clean_text) > len(details.get('description_full', '')):
                                details['additional_info'] = clean_text[:5000]  # –ü—Ä–≤–∏—Ç–µ 5000 –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏
                        except Exception as e:
                            self.logger.debug(f"BeautifulSoup –≥—Ä–µ—à–∫–∞: {e}")
                    else:
                        # –ê–∫–æ –Ω–µ–º–∞ BeautifulSoup, –∫–æ—Ä–∏—Å—Ç–∏ regex
                        clean_text = re.sub(r'<[^>]+>', '', page_source)
                        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
                        details['additional_info'] = clean_text[:3000]

            except Exception as e:
                self.logger.debug(f"–ù–µ –º–æ–∂–∞–º –¥–∞ –∑–µ–º–∞–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")

            # 4. –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –±–∏–ª–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            ticket_selectors = [
                ".ticket-info",
                ".ticket-details",
                ".price-info",
                "[class*='ticket']",
                "[class*='price']",
                ".buy-ticket",
                ".purchase"
            ]

            ticket_info = []
            for selector in ticket_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip()
                        if text and len(text) < 500 and text not in ticket_info:
                            ticket_info.append(text)
                except NoSuchElementException:
                    continue

            if ticket_info:
                details['ticket_info'] = ' | '.join(ticket_info)
                self.logger.info(f"    üé´ –ë–∏–ª–µ—Ç –∏–Ω—Ñ–æ: {details['ticket_info'][:100]}...")

        except Exception as e:
            self.logger.error(f"    ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ –¥–µ—Ç–∞–ª–∏: {e}")

        return details

    def find_event_cards(self) -> List:
        """–ù–∞—ò–¥–∏ –≥–∏ —Å–∏—Ç–µ event cards –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞"""
        card_selectors = [
            "a.k_event_link",  # –û–¥ –¥–∞–¥–µ–Ω–∏–æ—Ç HTML
            ".k_event_link",
            "[class*='event-card']",
            "[class*='event-item']",
            ".event-container a",
            ".events-list a"
        ]

        for selector in card_selectors:
            try:
                cards = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if cards:
                    self.logger.info(f"‚úÖ –ö–æ—Ä–∏—Å—Ç–∞–º —Å–µ–ª–µ–∫—Ç–æ—Ä '{selector}' - –Ω–∞—ò–¥–µ–Ω–∏ {len(cards)} cards")
                    return cards
            except Exception as e:
                self.logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä '{selector}' –Ω–µ —Ä–∞–±–æ—Ç–∏: {e}")
                continue

        self.logger.warning("‚ö†Ô∏è –ù–µ –º–æ–∂–∞–º –¥–∞ –Ω–∞—ò–¥–∞–º event cards!")
        return []

    def scroll_and_load_more(self):
        """–°–∫—Ä–æ–ª–∞—ò –∏ –ø—Ä–æ–±–∞—ò –¥–∞ –≤—á–∏—Ç–∞—à –ø–æ–≤–µ—ú–µ –Ω–∞—Å—Ç–∞–Ω–∏"""
        try:
            # –°–∫—Ä–æ–ª–∞—ò –¥–æ –¥–Ω–æ—Ç–æ
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)

            # –ü—Ä–æ–±–∞—ò –¥–∞ –Ω–∞—ò–¥–µ—à "Load More" –∫–æ–ø—á–µ
            load_more_selectors = [
                "#show_more_events",
                ".load-more",
                ".show-more",
                "[class*='load-more']",
                "[class*='show-more']"
            ]

            for selector in load_more_selectors:
                try:
                    button = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if button.is_displayed() and button.is_enabled():
                        self.logger.info(f"üîÑ –ö–ª–∏–∫–∞–º –Ω–∞ Load More –∫–æ–ø—á–µ")
                        self.driver.execute_script("arguments[0].click();", button)
                        time.sleep(3)
                        return True
                except NoSuchElementException:
                    continue

            return False

        except Exception as e:
            self.logger.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ scroll/load more: {e}")
            return False

    def scrape_events(self, max_load_attempts: int = 3) -> List[Dict]:
        """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞ –∑–∞ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ –Ω–∞—Å—Ç–∞–Ω–∏"""
        self.logger.info("üöÄ –ó–∞–ø–æ—á–Ω—É–≤–∞–º —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ –Ω–∞—Å—Ç–∞–Ω–∏ –æ–¥ karti.com.mk...")

        try:
            self.driver.get(self.events_url)
            self.logger.info(f"üìñ –í—á–∏—Ç–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {self.events_url}")
            time.sleep(5)

            all_events = []

            # –ü—Ä–æ–±–∞—ò –¥–∞ –≤—á–∏—Ç–∞—à –ø–æ–≤–µ—ú–µ –Ω–∞—Å—Ç–∞–Ω–∏
            for attempt in range(max_load_attempts):
                self.logger.info(f"\nüîç === –û–±–∏–¥ {attempt + 1}/{max_load_attempts} ===")

                # –ù–∞—ò–¥–∏ –≥–∏ event cards
                event_cards = self.find_event_cards()

                if not event_cards:
                    self.logger.warning("‚ùå –ù–µ–º–∞ event cards")
                    break

                self.logger.info(f"üìä –ù–∞—ò–¥–µ–Ω–∏ {len(event_cards)} event cards")

                # –ò–∑–≤–ª–µ—á–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ —Å–µ–∫–æ—ò card
                current_events = []
                for i, card in enumerate(event_cards):
                    try:
                        if self.debug and i < 3:  # Debug –ø—Ä–≤–∏—Ç–µ 3
                            self.logger.info(f"\n--- Card {i + 1} ---")

                        event_data = self.extract_event_from_card(card)

                        if event_data['title'] and event_data['event_id']:
                            current_events.append(event_data)
                            if self.debug and i < 3:
                                self.logger.info(f"‚úÖ {event_data['title']}")
                                self.logger.info(f"   üìÖ {event_data['date_start']}")
                                self.logger.info(f"   üè¢ {event_data['venue']}")
                                self.logger.info(f"   üí∞ {event_data['ticket_price_text']}")
                        else:
                            if self.debug and i < 3:
                                self.logger.warning(f"‚ùå Card {i + 1}: –ù–µ–º–∞ –≤–∞–ª–∏–¥–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏")

                    except Exception as e:
                        self.logger.error(f"‚ö†Ô∏è –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ card {i + 1}: {e}")
                        continue

                self.logger.info(f"‚úÖ –û–±–∏–¥ {attempt + 1}: –°–æ–±—Ä–∞–Ω–∏ {len(current_events)} –≤–∞–ª–∏–¥–Ω–∏ –Ω–∞—Å—Ç–∞–Ω–∏")
                all_events.extend(current_events)

                # –ü—Ä–æ–±–∞—ò –¥–∞ –≤—á–∏—Ç–∞—à –ø–æ–≤–µ—ú–µ
                if attempt < max_load_attempts - 1:
                    if not self.scroll_and_load_more():
                        self.logger.info("üîö –ù–µ–º–∞ –ø–æ–≤–µ—ú–µ –Ω–∞—Å—Ç–∞–Ω–∏ –∑–∞ –≤—á–∏—Ç—É–≤–∞—ö–µ")
                        break

            # –û—Ç—Å—Ç—Ä–∞–Ω–∏ –¥—É–ø–ª–∏–∫–∞—Ç–∏
            unique_events = self.remove_duplicates(all_events)
            self.logger.info(f"üßπ –ü–æ—Å–ª–µ –æ—Ç—Å—Ç—Ä–∞–Ω—É–≤–∞—ö–µ –¥—É–ø–ª–∏–∫–∞—Ç–∏: {len(unique_events)} —É–Ω–∏–∫–∞—Ç–Ω–∏ –Ω–∞—Å—Ç–∞–Ω–∏")

            # –§–∞–∑–∞ 2: –î–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏
            detailed_events = self.scrape_detailed_data(unique_events)

            return detailed_events

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –≥—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ: {e}")
            return []

    def remove_duplicates(self, events: List[Dict]) -> List[Dict]:
        """–û—Ç—Å—Ç—Ä–∞–Ω–∏ –¥—É–ø–ª–∏–∫–∞—Ç–∏ –≤—Ä–∑ –±–∞–∑–∞ –Ω–∞ event_id"""
        unique_events = []
        seen_ids = set()

        for event in events:
            event_id = event.get('event_id', '')
            if event_id and event_id not in seen_ids:
                unique_events.append(event)
                seen_ids.add(event_id)
            elif self.debug:
                self.logger.debug(f"üóëÔ∏è –î—É–ø–ª–∏–∫–∞—Ç –æ—Ç—Å—Ç—Ä–∞–Ω–µ—Ç: {event.get('title', 'No title')}")

        return unique_events

    def scrape_detailed_data(self, events: List[Dict]) -> List[Dict]:
        """–§–∞–∑–∞ 2: –°–æ–±–∏—Ä–∞—ò –¥–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –æ–¥ —Å–µ–∫–æ—ò –Ω–∞—Å—Ç–∞–Ω"""
        if not events:
            return []

        self.logger.info(f"\nüé¨ === –§–ê–ó–ê 2: –î–µ—Ç–∞–ª–Ω–∏ –ø–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ {len(events)} –Ω–∞—Å—Ç–∞–Ω–∏ ===")

        detailed_events = []
        for i, event in enumerate(events):
            self.logger.info(f"\nüé≠ {i + 1}/{len(events)} - {event['title']}")

            if event.get('url'):
                try:
                    details = self.scrape_event_details(event['url'])

                    # –ú–µ—Ä—ü–∏—Ä–∞—ò –≥–∏ –¥–µ—Ç–∞–ª–∏—Ç–µ
                    if details['description_full']:
                        event['description'] = details['description_full']
                    if details['organizer']:
                        event['organizer'] = details['organizer']
                    if details['contact_info']:
                        event['contact_info'] = details['contact_info']
                    if details['ticket_info']:
                        event['ticket_info'] = details['ticket_info']
                    if details['additional_info']:
                        event['additional_info'] = details['additional_info']

                    # –î–æ–¥–∞—ò –ø–∞—Ä—Å–∏—Ä–∞–Ω–∏ –¥–µ—Ç–∞–ª–∏ –∫–∞–∫–æ –ø–æ—Å–µ–±–Ω–∏ –ø–æ–ª–∏—ö–∞
                    parsed = details.get('parsed_details', {})
                    if parsed:
                        if parsed.get('parsed_price'):
                            event['parsed_price'] = parsed['parsed_price']
                        if parsed.get('parsed_time'):
                            event['parsed_time'] = parsed['parsed_time']
                        if parsed.get('parsed_venue'):
                            event['parsed_venue'] = parsed['parsed_venue']
                        if parsed.get('contact_info'):
                            event['parsed_contact'] = parsed['contact_info']
                        if parsed.get('event_type'):
                            event['parsed_event_type'] = parsed['event_type']
                        if parsed.get('additional_prices'):
                            event['all_prices'] = ', '.join(parsed['additional_prices'])

                    # –î–æ–¥–∞—ò —Å–∏—Ç–µ –æ—Å—Ç–∞–Ω–∞—Ç–∏ –¥–µ—Ç–∞–ª–∏
                    event.update({k: v for k, v in details.items() if v and k != 'parsed_details'})

                except Exception as e:
                    self.logger.error(f"    ‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –¥–µ—Ç–∞–ª–Ω–æ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ: {e}")
            else:
                self.logger.info("    ‚è≠Ô∏è –ü—Ä–µ—Å–∫–æ–∫–Ω—É–≤–∞–º (–Ω–µ–º–∞ –≤–∞–ª–∏–¥–µ–Ω –ª–∏–Ω–∫)")

            detailed_events.append(event)

        self.logger.info(f"\n‚úÖ –§–ê–ó–ê 2 –∑–∞–≤—Ä—à–µ–Ω–∞: {len(detailed_events)} –Ω–∞—Å—Ç–∞–Ω–∏ —Å–æ –¥–µ—Ç–∞–ª–∏")
        return detailed_events

    def save_to_csv(self, events: List[Dict], filename_suffix: str = "") -> str:
        """–ó–∞—á—É–≤–∞—ò –≥–∏ –Ω–∞—Å—Ç–∞–Ω–∏—Ç–µ –≤–æ CSV"""
        if not events:
            self.logger.warning("–ù–µ–º–∞ –Ω–∞—Å—Ç–∞–Ω–∏ –∑–∞ –∑–∞—á—É–≤—É–≤–∞—ö–µ")
            return ""

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if filename_suffix:
            filename = f"karti_events_{filename_suffix}_{timestamp}.csv"
        else:
            filename = f"karti_events_{timestamp}.csv"

        filepath = os.path.join(self.processed_data_dir, filename)

        try:
            df = pd.DataFrame(events)
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            self.logger.info(f"üíæ –ó–∞—á—É–≤–∞–Ω–∏ {len(events)} –Ω–∞—Å—Ç–∞–Ω–∏ –≤–æ: {filepath}")
            return filepath
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—á—É–≤—É–≤–∞—ö–µ: {e}")
            return ""

    def print_summary(self, events: List[Dict]):
        """–ü—Ä–∏–∫–∞–∂–∏ —Ä–µ–∑–∏–º–µ –æ–¥ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ—Ç–æ"""
        if not events:
            self.logger.info("üìä –ù–µ–º–∞ –Ω–∞—Å—Ç–∞–Ω–∏ –∑–∞ –ø—Ä–∏–∫–∞–∑")
            return

        self.logger.info(f"\nüìä === –†–ï–ó–ò–ú–ï ===")
        self.logger.info(f"–í–∫—É–ø–Ω–æ –Ω–∞—Å—Ç–∞–Ω–∏: {len(events)}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        with_description = sum(1 for e in events if e.get('description') and len(e['description']) > 50)
        with_organizer = sum(1 for e in events if e.get('organizer'))
        with_price = sum(1 for e in events if e.get('ticket_price_text'))
        with_parsed_price = sum(1 for e in events if e.get('parsed_price'))
        with_parsed_time = sum(1 for e in events if e.get('parsed_time'))
        with_venue = sum(1 for e in events if e.get('venue'))
        with_contact = sum(1 for e in events if e.get('contact_info') or e.get('parsed_contact'))
        free_events = sum(1 for e in events if e.get('ticket_free'))

        self.logger.info(f"–°–æ –æ–ø–∏—Å: {with_description}")
        self.logger.info(f"–°–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä: {with_organizer}")
        self.logger.info(f"–°–æ —Ü–µ–Ω–∞: {with_price}")
        self.logger.info(f"–°–æ –ø–∞—Ä—Å–∏—Ä–∞–Ω–∏ —Ü–µ–Ω–∏: {with_parsed_price}")
        self.logger.info(f"–°–æ –ø–∞—Ä—Å–∏—Ä–∞–Ω–æ –≤—Ä–µ–º–µ: {with_parsed_time}")
        self.logger.info(f"–°–æ venue: {with_venue}")
        self.logger.info(f"–°–æ –∫–æ–Ω—Ç–∞–∫—Ç: {with_contact}")
        self.logger.info(f"–ë–µ—Å–ø–ª–∞—Ç–Ω–∏: {free_events}")

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
        categories = {}
        for event in events:
            cat = event.get('category', '–ù–µ–ø–æ–∑–Ω–∞—Ç–æ')
            categories[cat] = categories.get(cat, 0) + 1

        self.logger.info(f"\n–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:")
        for cat, count in categories.items():
            self.logger.info(f"  {cat}: {count}")

        # –ü–∞—Ä—Å–∏—Ä–∞–Ω–∏ —Ç–∏–ø–æ–≤–∏ –Ω–∞—Å—Ç–∞–Ω–∏
        parsed_types = {}
        for event in events:
            p_type = event.get('parsed_event_type', '–ù–µ–ø–æ–∑–Ω–∞—Ç–æ')
            parsed_types[p_type] = parsed_types.get(p_type, 0) + 1

        if any(t != '–ù–µ–ø–æ–∑–Ω–∞—Ç–æ' for t in parsed_types.keys()):
            self.logger.info(f"\n–ü–∞—Ä—Å–∏—Ä–∞–Ω–∏ —Ç–∏–ø–æ–≤–∏:")
            for p_type, count in parsed_types.items():
                if p_type != '–ù–µ–ø–æ–∑–Ω–∞—Ç–æ':
                    self.logger.info(f"  {p_type}: {count}")

        # –ü—Ä–∏–º–µ—Ä–∏
        self.logger.info(f"\nüìã –ü—Ä–≤–∏—Ç–µ 3 –Ω–∞—Å—Ç–∞–Ω–∏:")
        for i, event in enumerate(events[:3]):
            self.logger.info(f"{i + 1}. {event.get('title', '–ë–µ–∑ –Ω–∞—Å–ª–æ–≤')}")
            self.logger.info(f"   üìÖ –î–∞—Ç—É–º: {event.get('date_start', '–ë–µ–∑ –¥–∞—Ç—É–º')}")
            self.logger.info(f"   üè¢ Venue: {event.get('venue', '–ë–µ–∑ venue')}")
            self.logger.info(f"   üí∞ –û—Ä–∏–≥–∏–Ω–∞–ª–Ω–∞ —Ü–µ–Ω–∞: {event.get('ticket_price_text', '–ë–µ–∑ —Ü–µ–Ω–∞')}")
            if event.get('parsed_price'):
                self.logger.info(f"   üí∞ –ü–∞—Ä—Å–∏—Ä–∞–Ω–∏ —Ü–µ–Ω–∏: {event.get('parsed_price')}")
            if event.get('parsed_time'):
                self.logger.info(f"   üïê –í—Ä–µ–º–µ: {event.get('parsed_time')}")
            if event.get('parsed_event_type'):
                self.logger.info(f"   üé≠ –¢–∏–ø: {event.get('parsed_event_type')}")
            self.logger.info(f"   üîó URL: {event.get('url', '–ë–µ–∑ URL')}")

    def run_full_scrape(self, max_load_attempts: int = 3, save_results: bool = True) -> List[Dict]:
        """–ò–∑–≤—Ä—à–∏ —Ü–µ–ª–æ—Å–Ω–æ —Å–∫—Ä–µ–ø–∏—Ä–∞—ö–µ"""
        try:
            self.logger.info("üöÄ === –ó–ê–ü–û–ß–ù–£–í–ê–ú –°–ö–†–ï–ü–ò–†–ê–ä–ï ===")

            # Setup
            self.setup_driver()

            # –°–∫—Ä–µ–ø–∏—Ä–∞—ò
            events = self.scrape_events(max_load_attempts)

            # –ó–∞—á—É–≤–∞—ò –∞–∫–æ –µ –ø–æ—Ç—Ä–µ–±–Ω–æ
            if save_results and events:
                self.save_to_csv(events, "final")

            # –ü—Ä–∏–∫–∞–∂–∏ —Ä–µ–∑–∏–º–µ
            self.print_summary(events)

            self.logger.info("‚úÖ === –°–ö–†–ï–ü–ò–†–ê–ä–ï–¢–û –ó–ê–í–†–®–ï–ù–û ===")
            return events

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –≥—Ä–µ—à–∫–∞: {e}")
            return []
        finally:
            self.close_driver()


def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—ò–∞"""
    print("üéØ Karti.com.mk Events Scraper")
    print("=" * 50)

    # –ö—Ä–µ–∏—Ä–∞—ò —Å–∫—Ä–µ–ø–µ—Ä —Å–æ debug
    scraper = KartiEventsScraper(debug=True)

    try:
        # –ò–∑–±—Ä–∏—à–∏ —Å—Ç–∞—Ä–∏ —Ñ–∞—ò–ª–æ–≤–∏
        scraper.clean_old_files()

        # –°–∫—Ä–µ–ø–∏—Ä–∞—ò –Ω–∞—Å—Ç–∞–Ω–∏
        events = scraper.run_full_scrape(max_load_attempts=3, save_results=True)

        if events:
            print(f"\nüéâ –£—Å–ø–µ—à–Ω–æ —Å–∫—Ä–µ–ø–∏—Ä–∞–Ω–∏ {len(events)} –Ω–∞—Å—Ç–∞–Ω–∏!")

            # –ü—Ä–∏–∫–∞–∂–∏ –Ω–µ–∫–æ–ª–∫—É –ø—Ä–∏–º–µ—Ä–∏
            print("\nüìã –ü—Ä–∏–º–µ—Ä–∏:")
            for i, event in enumerate(events[:5]):
                print(f"{i + 1}. {event.get('title', '–ë–µ–∑ –Ω–∞—Å–ª–æ–≤')}")
                print(f"   üìÖ –î–∞—Ç—É–º: {event.get('date_start', '–ë–µ–∑ –¥–∞—Ç—É–º')}")
                print(f"   üè¢ Venue: {event.get('venue', '–ù–µ–ø–æ–∑–Ω–∞—Ç')}")
                print(f"   üí∞ –¶–µ–Ω–∞: {event.get('ticket_price_text', '–ë–µ–∑ —Ü–µ–Ω–∞')}")
                print(f"   üé≠ –ö–∞—Ç–µ–≥–æ—Ä–∏—ò–∞: {event.get('category', '–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏—ò–∞')}")
                print(f"   üîó URL: {event.get('url', '–ë–µ–∑ URL')}")
                print(f"   üìù –û–ø–∏—Å: {event.get('description', '–ë–µ–∑ –æ–ø–∏—Å')[:100]}...")
                print()
        else:
            print("‚ùå –ù–µ —Å–µ —Å–∫—Ä–µ–ø–∏—Ä–∞–Ω–∏ –Ω–∞—Å—Ç–∞–Ω–∏. –ü—Ä–æ–≤–µ—Ä–µ—Ç–µ —ò–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—ò–∞—Ç–∞.")

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –°–∫—Ä–µ–ø–∏—Ä–∞—ö–µ—Ç–æ –µ –ø—Ä–µ–∫–∏–Ω–∞—Ç–æ –æ–¥ –∫–æ—Ä–∏—Å–Ω–∏–∫–æ—Ç")
    except Exception as e:
        print(f"\n‚ùå –ù–µ–æ—á–µ–∫—É–≤–∞–Ω–∞ –≥—Ä–µ—à–∫–∞: {e}")
    finally:
        print("\nüëã –ö—Ä–∞—ò –Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–∞—Ç–∞")


# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∏ utility —Ñ—É–Ω–∫—Ü–∏–∏
def scrape_single_event(url: str) -> Dict:
    """–°–∫—Ä–µ–ø–∏—Ä–∞—ò –µ–¥–µ–Ω –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –Ω–∞—Å—Ç–∞–Ω"""
    scraper = KartiEventsScraper(debug=True)
    try:
        scraper.setup_driver()
        details = scraper.scrape_event_details(url)
        return details
    finally:
        scraper.close_driver()


def test_selectors():
    """–¢–µ—Å—Ç —Ñ—É–Ω–∫—Ü–∏—ò–∞ –∑–∞ –¥–∞ —Å–µ —Ç–µ—Å—Ç–∏—Ä–∞–∞—Ç —Å–µ–ª–µ–∫—Ç–æ—Ä–∏—Ç–µ"""
    scraper = KartiEventsScraper(debug=True)
    try:
        scraper.setup_driver()
        scraper.driver.get("https://karti.com.mk")
        time.sleep(5)

        print("üîç –¢–µ—Å—Ç–∏—Ä–∞–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∏...")

        # –¢–µ—Å—Ç–∏—Ä–∞—ò —Ä–∞–∑–ª–∏—á–Ω–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∏
        test_selectors = [
            "a.k_event_link",
            ".k_event_link",
            ".k-event-list-event-title",
            ".k-events-event-date",
            ".k-events-venue-details",
            ".cost"
        ]

        for selector in test_selectors:
            try:
                elements = scraper.driver.find_elements(By.CSS_SELECTOR, selector)
                print(f"‚úÖ '{selector}': {len(elements)} –µ–ª–µ–º–µ–Ω—Ç–∏")
                if elements and len(elements) > 0:
                    print(f"   –ü—Ä–∏–º–µ—Ä: {elements[0].text[:50]}...")
            except Exception as e:
                print(f"‚ùå '{selector}': –ì—Ä–µ—à–∫–∞ - {e}")

        # –¢–µ—Å—Ç–∏—Ä–∞—ò –µ–¥–µ–Ω card –¥–µ—Ç–∞–ª–Ω–æ
        cards = scraper.driver.find_elements(By.CSS_SELECTOR, "a.k_event_link")
        if cards:
            print(f"\nüî¨ –î–µ—Ç–∞–ª–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –ø—Ä–≤–∏–æ—Ç card:")
            card = cards[0]
            print(f"   Tag: {card.tag_name}")
            print(f"   Class: {card.get_attribute('class')}")
            print(f"   Href: {card.get_attribute('href')}")
            print(f"   HTML: {card.get_attribute('outerHTML')[:300]}...")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–¥-–µ–ª–µ–º–µ–Ω—Ç–∏
            sub_elements = [
                ".k-event-list-event-title",
                ".k-events-event-date",
                ".k-events-venue-details",
                ".cost",
                "h2",
                "img"
            ]

            for sub_sel in sub_elements:
                try:
                    sub_elem = card.find_element(By.CSS_SELECTOR, sub_sel)
                    print(f"   ‚úÖ {sub_sel}: '{sub_elem.text[:30]}'")
                except:
                    print(f"   ‚ùå {sub_sel}: –ù–µ –Ω–∞—ò–¥–µ–Ω")

    finally:
        scraper.close_driver()


if __name__ == "__main__":
    main()